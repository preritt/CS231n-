{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HARfeedbackFullDatasetEpochBasedADAM0430_Test95p01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/CS231n-/blob/master/HARfeedbackFullDatasetEpochBasedADAM0430_Test95p01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "166e8095-a1b5-46f4-a19c-af52c0329a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>551</th>\n",
              "      <th>552</th>\n",
              "      <th>553</th>\n",
              "      <th>554</th>\n",
              "      <th>555</th>\n",
              "      <th>556</th>\n",
              "      <th>557</th>\n",
              "      <th>558</th>\n",
              "      <th>559</th>\n",
              "      <th>560</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.031224</td>\n",
              "      <td>0.052527</td>\n",
              "      <td>0.115961</td>\n",
              "      <td>-0.875200</td>\n",
              "      <td>-0.957705</td>\n",
              "      <td>-0.900766</td>\n",
              "      <td>-0.868209</td>\n",
              "      <td>-0.959311</td>\n",
              "      <td>-0.903576</td>\n",
              "      <td>-0.871754</td>\n",
              "      <td>...</td>\n",
              "      <td>0.868067</td>\n",
              "      <td>-1.420373</td>\n",
              "      <td>-1.031076</td>\n",
              "      <td>0.041417</td>\n",
              "      <td>-0.618447</td>\n",
              "      <td>1.179824</td>\n",
              "      <td>0.885911</td>\n",
              "      <td>-0.877134</td>\n",
              "      <td>0.056712</td>\n",
              "      <td>0.119820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.176101</td>\n",
              "      <td>0.356526</td>\n",
              "      <td>-0.417228</td>\n",
              "      <td>0.311962</td>\n",
              "      <td>0.450204</td>\n",
              "      <td>0.852550</td>\n",
              "      <td>0.306335</td>\n",
              "      <td>0.367644</td>\n",
              "      <td>0.888266</td>\n",
              "      <td>0.245780</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.124388</td>\n",
              "      <td>0.568143</td>\n",
              "      <td>0.749813</td>\n",
              "      <td>0.297311</td>\n",
              "      <td>0.234130</td>\n",
              "      <td>1.557127</td>\n",
              "      <td>1.772883</td>\n",
              "      <td>-0.028307</td>\n",
              "      <td>0.797992</td>\n",
              "      <td>1.281095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.401526</td>\n",
              "      <td>-0.255999</td>\n",
              "      <td>-0.227483</td>\n",
              "      <td>0.724607</td>\n",
              "      <td>1.012197</td>\n",
              "      <td>0.537364</td>\n",
              "      <td>0.702820</td>\n",
              "      <td>1.059839</td>\n",
              "      <td>0.485615</td>\n",
              "      <td>1.002515</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247473</td>\n",
              "      <td>1.222819</td>\n",
              "      <td>1.111675</td>\n",
              "      <td>-1.753009</td>\n",
              "      <td>-0.472243</td>\n",
              "      <td>1.453390</td>\n",
              "      <td>0.416217</td>\n",
              "      <td>-0.390767</td>\n",
              "      <td>0.767157</td>\n",
              "      <td>0.638829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.241090</td>\n",
              "      <td>0.149696</td>\n",
              "      <td>0.354921</td>\n",
              "      <td>-0.829910</td>\n",
              "      <td>-0.829986</td>\n",
              "      <td>-0.777500</td>\n",
              "      <td>-0.821882</td>\n",
              "      <td>-0.817905</td>\n",
              "      <td>-0.772262</td>\n",
              "      <td>-0.844885</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025308</td>\n",
              "      <td>-0.373414</td>\n",
              "      <td>-0.461477</td>\n",
              "      <td>-0.076678</td>\n",
              "      <td>-0.191304</td>\n",
              "      <td>0.185464</td>\n",
              "      <td>-0.753572</td>\n",
              "      <td>-0.179145</td>\n",
              "      <td>0.956654</td>\n",
              "      <td>0.816782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.509378</td>\n",
              "      <td>0.598757</td>\n",
              "      <td>1.235366</td>\n",
              "      <td>1.671994</td>\n",
              "      <td>1.222057</td>\n",
              "      <td>2.101020</td>\n",
              "      <td>1.609877</td>\n",
              "      <td>1.248976</td>\n",
              "      <td>1.892042</td>\n",
              "      <td>1.919040</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105242</td>\n",
              "      <td>0.009285</td>\n",
              "      <td>-0.345760</td>\n",
              "      <td>0.989375</td>\n",
              "      <td>1.564256</td>\n",
              "      <td>-0.593559</td>\n",
              "      <td>0.870385</td>\n",
              "      <td>-0.557192</td>\n",
              "      <td>0.373064</td>\n",
              "      <td>0.783913</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 561 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4         5         6    \\\n",
              "0  0.031224  0.052527  0.115961 -0.875200 -0.957705 -0.900766 -0.868209   \n",
              "1 -0.176101  0.356526 -0.417228  0.311962  0.450204  0.852550  0.306335   \n",
              "2  0.401526 -0.255999 -0.227483  0.724607  1.012197  0.537364  0.702820   \n",
              "3  0.241090  0.149696  0.354921 -0.829910 -0.829986 -0.777500 -0.821882   \n",
              "4 -0.509378  0.598757  1.235366  1.671994  1.222057  2.101020  1.609877   \n",
              "\n",
              "        7         8         9    ...       551       552       553       554  \\\n",
              "0 -0.959311 -0.903576 -0.871754  ...  0.868067 -1.420373 -1.031076  0.041417   \n",
              "1  0.367644  0.888266  0.245780  ... -0.124388  0.568143  0.749813  0.297311   \n",
              "2  1.059839  0.485615  1.002515  ...  0.247473  1.222819  1.111675 -1.753009   \n",
              "3 -0.817905 -0.772262 -0.844885  ... -0.025308 -0.373414 -0.461477 -0.076678   \n",
              "4  1.248976  1.892042  1.919040  ... -0.105242  0.009285 -0.345760  0.989375   \n",
              "\n",
              "        555       556       557       558       559       560  \n",
              "0 -0.618447  1.179824  0.885911 -0.877134  0.056712  0.119820  \n",
              "1  0.234130  1.557127  1.772883 -0.028307  0.797992  1.281095  \n",
              "2 -0.472243  1.453390  0.416217 -0.390767  0.767157  0.638829  \n",
              "3 -0.191304  0.185464 -0.753572 -0.179145  0.956654  0.816782  \n",
              "4  1.564256 -0.593559  0.870385 -0.557192  0.373064  0.783913  \n",
              "\n",
              "[5 rows x 561 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "f8bc5cd5-157d-4b81-fae3-23feba8d837b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  3\n",
              "1  1\n",
              "2  0\n",
              "3  4\n",
              "4  2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "538776af-5016-41d7-ddcc-f8fdb7818fd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "b33c2e92-d1b6-4d96-883b-324e46e3b1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1471, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "6386ad83-9c49-44e2-8428-6107b822304e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pDOMf8vCQFNW"
      },
      "cell_type": "markdown",
      "source": [
        "## without using vaidation data for fitting"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "06c8b3b5-03b6-41ed-87e0-bb87d6dd3476",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5126
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(374, ), max_iter=500, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.01)\n",
        "# Test set score: 0.950119\n",
        "\n",
        "\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52720526\n",
            "Iteration 2, loss = 0.15379691\n",
            "Iteration 3, loss = 0.11074311\n",
            "Iteration 4, loss = 0.08947817\n",
            "Iteration 5, loss = 0.07609836\n",
            "Iteration 6, loss = 0.06703077\n",
            "Iteration 7, loss = 0.06092138\n",
            "Iteration 8, loss = 0.05482786\n",
            "Iteration 9, loss = 0.05074759\n",
            "Iteration 10, loss = 0.04820633\n",
            "Iteration 11, loss = 0.04462717\n",
            "Iteration 12, loss = 0.04117033\n",
            "Iteration 13, loss = 0.03949230\n",
            "Iteration 14, loss = 0.03816921\n",
            "Iteration 15, loss = 0.03526902\n",
            "Iteration 16, loss = 0.03338227\n",
            "Iteration 17, loss = 0.03256753\n",
            "Iteration 18, loss = 0.03047405\n",
            "Iteration 19, loss = 0.02924046\n",
            "Iteration 20, loss = 0.02849386\n",
            "Iteration 21, loss = 0.02730756\n",
            "Iteration 22, loss = 0.02559763\n",
            "Iteration 23, loss = 0.02459467\n",
            "Iteration 24, loss = 0.02391017\n",
            "Iteration 25, loss = 0.02354070\n",
            "Iteration 26, loss = 0.02216005\n",
            "Iteration 27, loss = 0.02149137\n",
            "Iteration 28, loss = 0.02112266\n",
            "Iteration 29, loss = 0.02016297\n",
            "Iteration 30, loss = 0.01943691\n",
            "Iteration 31, loss = 0.01848743\n",
            "Iteration 32, loss = 0.01833975\n",
            "Iteration 33, loss = 0.01734477\n",
            "Iteration 34, loss = 0.01683132\n",
            "Iteration 35, loss = 0.01656447\n",
            "Iteration 36, loss = 0.01629328\n",
            "Iteration 37, loss = 0.01554519\n",
            "Iteration 38, loss = 0.01475836\n",
            "Iteration 39, loss = 0.01461295\n",
            "Iteration 40, loss = 0.01419653\n",
            "Iteration 41, loss = 0.01353610\n",
            "Iteration 42, loss = 0.01370225\n",
            "Iteration 43, loss = 0.01320427\n",
            "Iteration 44, loss = 0.01308621\n",
            "Iteration 45, loss = 0.01274597\n",
            "Iteration 46, loss = 0.01203195\n",
            "Iteration 47, loss = 0.01174829\n",
            "Iteration 48, loss = 0.01125364\n",
            "Iteration 49, loss = 0.01074622\n",
            "Iteration 50, loss = 0.01062621\n",
            "Iteration 51, loss = 0.01044433\n",
            "Iteration 52, loss = 0.01012032\n",
            "Iteration 53, loss = 0.00998317\n",
            "Iteration 54, loss = 0.00957855\n",
            "Iteration 55, loss = 0.00919682\n",
            "Iteration 56, loss = 0.00903952\n",
            "Iteration 57, loss = 0.00882828\n",
            "Iteration 58, loss = 0.00842398\n",
            "Iteration 59, loss = 0.00830306\n",
            "Iteration 60, loss = 0.00800349\n",
            "Iteration 61, loss = 0.00785930\n",
            "Iteration 62, loss = 0.00785182\n",
            "Iteration 63, loss = 0.00758100\n",
            "Iteration 64, loss = 0.00740849\n",
            "Iteration 65, loss = 0.00748268\n",
            "Iteration 66, loss = 0.00716864\n",
            "Iteration 67, loss = 0.00700393\n",
            "Iteration 68, loss = 0.00692167\n",
            "Iteration 69, loss = 0.00658257\n",
            "Iteration 70, loss = 0.00648939\n",
            "Iteration 71, loss = 0.00624277\n",
            "Iteration 72, loss = 0.00612378\n",
            "Iteration 73, loss = 0.00603359\n",
            "Iteration 74, loss = 0.00594559\n",
            "Iteration 75, loss = 0.00585920\n",
            "Iteration 76, loss = 0.00570434\n",
            "Iteration 77, loss = 0.00561283\n",
            "Iteration 78, loss = 0.00554028\n",
            "Iteration 79, loss = 0.00541069\n",
            "Iteration 80, loss = 0.00524976\n",
            "Iteration 81, loss = 0.00527214\n",
            "Iteration 82, loss = 0.00516337\n",
            "Iteration 83, loss = 0.00497239\n",
            "Iteration 84, loss = 0.00485493\n",
            "Iteration 85, loss = 0.00490756\n",
            "Iteration 86, loss = 0.00467278\n",
            "Iteration 87, loss = 0.00460029\n",
            "Iteration 88, loss = 0.00454493\n",
            "Iteration 89, loss = 0.00442256\n",
            "Iteration 90, loss = 0.00432667\n",
            "Iteration 91, loss = 0.00433931\n",
            "Iteration 92, loss = 0.00421722\n",
            "Iteration 93, loss = 0.00419655\n",
            "Iteration 94, loss = 0.00406313\n",
            "Iteration 95, loss = 0.00407564\n",
            "Iteration 96, loss = 0.00401053\n",
            "Iteration 97, loss = 0.00392400\n",
            "Iteration 98, loss = 0.00386804\n",
            "Iteration 99, loss = 0.00379496\n",
            "Iteration 100, loss = 0.00373337\n",
            "Iteration 101, loss = 0.00365417\n",
            "Iteration 102, loss = 0.00360392\n",
            "Iteration 103, loss = 0.00356796\n",
            "Iteration 104, loss = 0.00349700\n",
            "Iteration 105, loss = 0.00347712\n",
            "Iteration 106, loss = 0.00346129\n",
            "Iteration 107, loss = 0.00341398\n",
            "Iteration 108, loss = 0.00332927\n",
            "Iteration 109, loss = 0.00332159\n",
            "Iteration 110, loss = 0.00330862\n",
            "Iteration 111, loss = 0.00318258\n",
            "Iteration 112, loss = 0.00317291\n",
            "Iteration 113, loss = 0.00313192\n",
            "Iteration 114, loss = 0.00312075\n",
            "Iteration 115, loss = 0.00306214\n",
            "Iteration 116, loss = 0.00303800\n",
            "Iteration 117, loss = 0.00300883\n",
            "Iteration 118, loss = 0.00297746\n",
            "Iteration 119, loss = 0.00287678\n",
            "Iteration 120, loss = 0.00285229\n",
            "Iteration 121, loss = 0.00280417\n",
            "Iteration 122, loss = 0.00281288\n",
            "Iteration 123, loss = 0.00279715\n",
            "Iteration 124, loss = 0.00272476\n",
            "Iteration 125, loss = 0.00271742\n",
            "Iteration 126, loss = 0.00268767\n",
            "Iteration 127, loss = 0.00261441\n",
            "Iteration 128, loss = 0.00265474\n",
            "Iteration 129, loss = 0.00261967\n",
            "Iteration 130, loss = 0.00256700\n",
            "Iteration 131, loss = 0.00249650\n",
            "Iteration 132, loss = 0.00251667\n",
            "Iteration 133, loss = 0.00249242\n",
            "Iteration 134, loss = 0.00244083\n",
            "Iteration 135, loss = 0.00249760\n",
            "Iteration 136, loss = 0.00237943\n",
            "Iteration 137, loss = 0.00237679\n",
            "Iteration 138, loss = 0.00234850\n",
            "Iteration 139, loss = 0.00232762\n",
            "Iteration 140, loss = 0.00229602\n",
            "Iteration 141, loss = 0.00230112\n",
            "Iteration 142, loss = 0.00225280\n",
            "Iteration 143, loss = 0.00222079\n",
            "Iteration 144, loss = 0.00221551\n",
            "Iteration 145, loss = 0.00218910\n",
            "Iteration 146, loss = 0.00220109\n",
            "Iteration 147, loss = 0.00214222\n",
            "Iteration 148, loss = 0.00212741\n",
            "Iteration 149, loss = 0.00211983\n",
            "Iteration 150, loss = 0.00208963\n",
            "Iteration 151, loss = 0.00208430\n",
            "Iteration 152, loss = 0.00205445\n",
            "Iteration 153, loss = 0.00202581\n",
            "Iteration 154, loss = 0.00201077\n",
            "Iteration 155, loss = 0.00198594\n",
            "Iteration 156, loss = 0.00201227\n",
            "Iteration 157, loss = 0.00197451\n",
            "Iteration 158, loss = 0.00197394\n",
            "Iteration 159, loss = 0.00191715\n",
            "Iteration 160, loss = 0.00191562\n",
            "Iteration 161, loss = 0.00192284\n",
            "Iteration 162, loss = 0.00191362\n",
            "Iteration 163, loss = 0.00187164\n",
            "Iteration 164, loss = 0.00184135\n",
            "Iteration 165, loss = 0.00183465\n",
            "Iteration 166, loss = 0.00182088\n",
            "Iteration 167, loss = 0.00180899\n",
            "Iteration 168, loss = 0.00180355\n",
            "Iteration 169, loss = 0.00177716\n",
            "Iteration 170, loss = 0.00176685\n",
            "Iteration 171, loss = 0.00175030\n",
            "Iteration 172, loss = 0.00175049\n",
            "Iteration 173, loss = 0.00171984\n",
            "Iteration 174, loss = 0.00171184\n",
            "Iteration 175, loss = 0.00170115\n",
            "Iteration 176, loss = 0.00169457\n",
            "Iteration 177, loss = 0.00166902\n",
            "Iteration 178, loss = 0.00166703\n",
            "Iteration 179, loss = 0.00163954\n",
            "Iteration 180, loss = 0.00163217\n",
            "Iteration 181, loss = 0.00163243\n",
            "Iteration 182, loss = 0.00162558\n",
            "Iteration 183, loss = 0.00159687\n",
            "Iteration 184, loss = 0.00164311\n",
            "Iteration 185, loss = 0.00157965\n",
            "Iteration 186, loss = 0.00155642\n",
            "Iteration 187, loss = 0.00156807\n",
            "Iteration 188, loss = 0.00153528\n",
            "Iteration 189, loss = 0.00155032\n",
            "Iteration 190, loss = 0.00152579\n",
            "Iteration 191, loss = 0.00152152\n",
            "Iteration 192, loss = 0.00152949\n",
            "Iteration 193, loss = 0.00149234\n",
            "Iteration 194, loss = 0.00149090\n",
            "Iteration 195, loss = 0.00149407\n",
            "Iteration 196, loss = 0.00146058\n",
            "Iteration 197, loss = 0.00146076\n",
            "Iteration 198, loss = 0.00144024\n",
            "Iteration 199, loss = 0.00146338\n",
            "Iteration 200, loss = 0.00143834\n",
            "Iteration 201, loss = 0.00144446\n",
            "Iteration 202, loss = 0.00140414\n",
            "Iteration 203, loss = 0.00139807\n",
            "Iteration 204, loss = 0.00139003\n",
            "Iteration 205, loss = 0.00138725\n",
            "Iteration 206, loss = 0.00138091\n",
            "Iteration 207, loss = 0.00136549\n",
            "Iteration 208, loss = 0.00136043\n",
            "Iteration 209, loss = 0.00136405\n",
            "Iteration 210, loss = 0.00134716\n",
            "Iteration 211, loss = 0.00133971\n",
            "Iteration 212, loss = 0.00133517\n",
            "Iteration 213, loss = 0.00133948\n",
            "Iteration 214, loss = 0.00131070\n",
            "Iteration 215, loss = 0.00130429\n",
            "Iteration 216, loss = 0.00129578\n",
            "Iteration 217, loss = 0.00129759\n",
            "Iteration 218, loss = 0.00128454\n",
            "Iteration 219, loss = 0.00127488\n",
            "Iteration 220, loss = 0.00127705\n",
            "Iteration 221, loss = 0.00125503\n",
            "Iteration 222, loss = 0.00125035\n",
            "Iteration 223, loss = 0.00124939\n",
            "Iteration 224, loss = 0.00123950\n",
            "Iteration 225, loss = 0.00124269\n",
            "Iteration 226, loss = 0.00122294\n",
            "Iteration 227, loss = 0.00121358\n",
            "Iteration 228, loss = 0.00121795\n",
            "Iteration 229, loss = 0.00121993\n",
            "Iteration 230, loss = 0.00120013\n",
            "Iteration 231, loss = 0.00120214\n",
            "Iteration 232, loss = 0.00118955\n",
            "Iteration 233, loss = 0.00119117\n",
            "Iteration 234, loss = 0.00117541\n",
            "Iteration 235, loss = 0.00118291\n",
            "Iteration 236, loss = 0.00115907\n",
            "Iteration 237, loss = 0.00115156\n",
            "Iteration 238, loss = 0.00115538\n",
            "Iteration 239, loss = 0.00113846\n",
            "Iteration 240, loss = 0.00114294\n",
            "Iteration 241, loss = 0.00113441\n",
            "Iteration 242, loss = 0.00113424\n",
            "Iteration 243, loss = 0.00113737\n",
            "Iteration 244, loss = 0.00112972\n",
            "Iteration 245, loss = 0.00111104\n",
            "Iteration 246, loss = 0.00111092\n",
            "Iteration 247, loss = 0.00110113\n",
            "Iteration 248, loss = 0.00109721\n",
            "Iteration 249, loss = 0.00108678\n",
            "Iteration 250, loss = 0.00108536\n",
            "Iteration 251, loss = 0.00108186\n",
            "Iteration 252, loss = 0.00108212\n",
            "Iteration 253, loss = 0.00107221\n",
            "Iteration 254, loss = 0.00105986\n",
            "Iteration 255, loss = 0.00105490\n",
            "Iteration 256, loss = 0.00106770\n",
            "Iteration 257, loss = 0.00104865\n",
            "Iteration 258, loss = 0.00105722\n",
            "Iteration 259, loss = 0.00104949\n",
            "Iteration 260, loss = 0.00104859\n",
            "Iteration 261, loss = 0.00103729\n",
            "Iteration 262, loss = 0.00102181\n",
            "Iteration 263, loss = 0.00102176\n",
            "Iteration 264, loss = 0.00101276\n",
            "Iteration 265, loss = 0.00100853\n",
            "Iteration 266, loss = 0.00100495\n",
            "Iteration 267, loss = 0.00100003\n",
            "Iteration 268, loss = 0.00100249\n",
            "Iteration 269, loss = 0.00099136\n",
            "Iteration 270, loss = 0.00099639\n",
            "Iteration 271, loss = 0.00098411\n",
            "Iteration 272, loss = 0.00097758\n",
            "Iteration 273, loss = 0.00097843\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(374,), learning_rate='constant',\n",
              "       learning_rate_init=0.01, max_iter=500, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "d41842df-9a59-4967-e5ca-f6c77fa52b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "d5176a2b-e49d-4987-cba0-b7ce8b3ac61c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.982324949014276"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "e8d298fe-e700-4628-9997-2517b1214d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9463861554122837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "eb2fa236-ead1-46f9-f978-7f5cba972e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 561 -> 374 -> 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "d9a0fb38-96a4-41ba-942f-13b3b1cc7a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5881, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "outputId": "8b050473-91a0-423c-d475-5fbb15989ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Rerun the same thing in tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ## Building the graph - Best!\n",
        "# saver = tf.train.Saver()\n",
        "# learning_rate = 0.001\n",
        "# hid_neuron = [374]\n",
        "# num_steps = 20000\n",
        "# batch_size = 200\n",
        "# train_losses = []\n",
        "# test_acc = []\n",
        "# X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "# Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "# def neural_net(x,train = True):\n",
        "#     layer_outputs = []\n",
        "#     layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "#     layer_1 = tf.nn.relu(layer_1)\n",
        "# #     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "# #     layer_2 = tf.nn.relu(layer_2)\n",
        "#     out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_outputs.append(out_layer)\n",
        "#     return out_layer\n",
        "\n",
        "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "# train_op = optimizer.minimize(loss)\n",
        "# correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "#   ### Initialization and running the model\n",
        "# with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "#     best_accuracy_valid = 0\n",
        "#     for step in range(0, num_steps):\n",
        "#         batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "#         sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "#         if step % 1000 == 0:\n",
        "#             train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "#             train_losses.append(train_loss)\n",
        "#             validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "#             if step%1000 == 0:\n",
        "#               print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "#               print()\n",
        "#               if (validation_accuracy >= best_accuracy_valid):\n",
        "#                 best_accuracy_valid = validation_accuracy\n",
        "#                 saver.save(sess, './statlog_letter')\n",
        "#                 test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#     print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "#     print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "#     print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UpCtcB9hQFPI",
        "outputId": "c8dd2c5d-bf88-4efa-e8f0-08fc1c4e6822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1471, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mT7SryMuQFPO"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-test"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K-zBUEuGwV98",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E91ru7-owV5i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 374\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlDkpoIzcLL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53cd2f55-76c6-408e-9bd8-00f627333007"
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5881, 561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Hqw9g6e-cL3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b503e64b-587f-4835-899d-fb0d094c805f"
      },
      "cell_type": "code",
      "source": [
        "5881/200"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "GUH5tpXwcUdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "baeda80a-bfba-4277-8fc4-e02805ca2b0a"
      },
      "cell_type": "code",
      "source": [
        "100000/30"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3333.3333333333335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "1dqcFndAcZyP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 3333"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXzaScAbcaj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle  #train_data, train_label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIJshIO5b1w6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train using epoch based methos"
      ]
    },
    {
      "metadata": {
        "id": "crEGEj10b4k_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17187
        },
        "outputId": "05790760-3d76-4c0d-f132-4c2dddcf1ce9"
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 100000\n",
        "batch_size = 4112\n",
        "BATCH_SIZE = batch_size\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 10\n",
        "\n",
        "\n",
        "###\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = train_data.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "epoch_track = []\n",
        "###\n",
        "learning_rate = 0.0001\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "#############\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for i in range(EPOCHS):\n",
        "      X_train, y_train = shuffle(train_data, train_label_one_hot)\n",
        "      \n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "            step = 0\n",
        "          else:\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "          sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if i % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: X_train,Y: y_train})\n",
        "          train_accuracy.append(train_acc)\n",
        "          print(\"Epoch \" + str(i) + '/' + str(EPOCHS) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          train_losses.append(train_loss)\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "          val_accuracy.append(validation_accuracy)\n",
        "          if step%plot_every == 0:\n",
        "            print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "              saver.save(sess, './HarFull')\n",
        "              G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/3333, training loss= 0.015173976, training acc= 99.72793459892273%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 10/3333, training loss= 0.0033024119, training acc= 100.0%\n",
            "Validation Accuracy 97.9605712890625 ...\n",
            "\n",
            "Epoch 20/3333, training loss= 0.00071133894, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 30/3333, training loss= 0.00059565506, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 40/3333, training loss= 0.0005448497, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 50/3333, training loss= 0.00052220956, training acc= 100.0%\n",
            "Validation Accuracy 98.02854919433594 ...\n",
            "\n",
            "Epoch 60/3333, training loss= 0.0005072471, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 70/3333, training loss= 0.0004953801, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 80/3333, training loss= 0.00048545317, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 90/3333, training loss= 0.00047655485, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 100/3333, training loss= 0.00046867007, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 110/3333, training loss= 0.00046142194, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 120/3333, training loss= 0.00045467823, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 130/3333, training loss= 0.00044825644, training acc= 100.0%\n",
            "Validation Accuracy 98.0965347290039 ...\n",
            "\n",
            "Epoch 140/3333, training loss= 0.00044216332, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 150/3333, training loss= 0.00043624215, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 160/3333, training loss= 0.00043062563, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 170/3333, training loss= 0.0004253568, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 180/3333, training loss= 0.00042010288, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 190/3333, training loss= 0.0004150478, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 200/3333, training loss= 0.00041016468, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 210/3333, training loss= 0.00040533167, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 220/3333, training loss= 0.0004005695, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 230/3333, training loss= 0.00039601498, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 240/3333, training loss= 0.00039140155, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 250/3333, training loss= 0.00038704684, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 260/3333, training loss= 0.00038247046, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 270/3333, training loss= 0.00037811825, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 280/3333, training loss= 0.00037375357, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 290/3333, training loss= 0.00036969956, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 300/3333, training loss= 0.00036611638, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 310/3333, training loss= 0.00036112458, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 320/3333, training loss= 0.00035699483, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 330/3333, training loss= 0.0003531264, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 340/3333, training loss= 0.00034898767, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 350/3333, training loss= 0.00034501954, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 360/3333, training loss= 0.00034109046, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 370/3333, training loss= 0.0003374593, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 380/3333, training loss= 0.00033360106, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 390/3333, training loss= 0.00032969503, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 400/3333, training loss= 0.00032584535, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 410/3333, training loss= 0.00032208368, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 420/3333, training loss= 0.00031848112, training acc= 100.0%\n",
            "Validation Accuracy 98.16452026367188 ...\n",
            "\n",
            "Epoch 430/3333, training loss= 0.00031530127, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 440/3333, training loss= 0.00031121506, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 450/3333, training loss= 0.00030762833, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 460/3333, training loss= 0.00030407717, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 470/3333, training loss= 0.00030054612, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 480/3333, training loss= 0.00029708003, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 490/3333, training loss= 0.00029361752, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 500/3333, training loss= 0.00029038973, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 510/3333, training loss= 0.0002869377, training acc= 100.0%\n",
            "Validation Accuracy 98.23249816894531 ...\n",
            "\n",
            "Epoch 520/3333, training loss= 0.00028359983, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 530/3333, training loss= 0.00028023892, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 540/3333, training loss= 0.00027702196, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 550/3333, training loss= 0.0002737816, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 560/3333, training loss= 0.00027062252, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 570/3333, training loss= 0.0002674801, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 580/3333, training loss= 0.0002643278, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 590/3333, training loss= 0.0002612931, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 600/3333, training loss= 0.0002582592, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 610/3333, training loss= 0.00025522435, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 620/3333, training loss= 0.00025225576, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 630/3333, training loss= 0.00024924026, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 640/3333, training loss= 0.00024625447, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 650/3333, training loss= 0.00024335245, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 660/3333, training loss= 0.00024053529, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 670/3333, training loss= 0.00023762896, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 680/3333, training loss= 0.00023484549, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 690/3333, training loss= 0.00023208202, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 700/3333, training loss= 0.000229304, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 710/3333, training loss= 0.00022658477, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 720/3333, training loss= 0.0002239175, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 730/3333, training loss= 0.0002213038, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 740/3333, training loss= 0.00021861502, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 750/3333, training loss= 0.00021598478, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 760/3333, training loss= 0.00021363431, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 770/3333, training loss= 0.00021089136, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 780/3333, training loss= 0.00020837264, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 790/3333, training loss= 0.00020587465, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 800/3333, training loss= 0.00020340743, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 810/3333, training loss= 0.00020099964, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 820/3333, training loss= 0.00019853289, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 830/3333, training loss= 0.00019615512, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 840/3333, training loss= 0.00019391192, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 850/3333, training loss= 0.0001914669, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 860/3333, training loss= 0.00018923313, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 870/3333, training loss= 0.00018694808, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 880/3333, training loss= 0.00018477379, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 890/3333, training loss= 0.00018254812, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 900/3333, training loss= 0.00018033323, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 910/3333, training loss= 0.00017815713, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 920/3333, training loss= 0.00017604363, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 930/3333, training loss= 0.00017399462, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 940/3333, training loss= 0.00017192772, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 950/3333, training loss= 0.00016980091, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 960/3333, training loss= 0.00016774023, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 970/3333, training loss= 0.00016580064, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 980/3333, training loss= 0.00016379656, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 990/3333, training loss= 0.0001617744, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1000/3333, training loss= 0.00015983051, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1010/3333, training loss= 0.00015791562, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1020/3333, training loss= 0.00015608755, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1030/3333, training loss= 0.00015419985, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1040/3333, training loss= 0.0001523596, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1050/3333, training loss= 0.00015047211, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1060/3333, training loss= 0.0001486364, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1070/3333, training loss= 0.00014689745, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1080/3333, training loss= 0.00014507827, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1090/3333, training loss= 0.0001433049, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1100/3333, training loss= 0.00014160392, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1110/3333, training loss= 0.00013990546, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1120/3333, training loss= 0.00013819136, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1130/3333, training loss= 0.00013656277, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1140/3333, training loss= 0.0001348946, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1150/3333, training loss= 0.00013325026, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1160/3333, training loss= 0.00013162926, training acc= 100.0%\n",
            "Validation Accuracy 98.30047607421875 ...\n",
            "\n",
            "Epoch 1170/3333, training loss= 0.00013017154, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1180/3333, training loss= 0.00012853672, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1190/3333, training loss= 0.00012702294, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1200/3333, training loss= 0.00012551056, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1210/3333, training loss= 0.00012394067, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1220/3333, training loss= 0.00012245812, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1230/3333, training loss= 0.0001210018, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1240/3333, training loss= 0.00011953543, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1250/3333, training loss= 0.00011814137, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1260/3333, training loss= 0.0001167095, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1270/3333, training loss= 0.000115337585, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1280/3333, training loss= 0.00011397311, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1290/3333, training loss= 0.000112556176, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1300/3333, training loss= 0.00011120569, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1310/3333, training loss= 0.000109853725, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1320/3333, training loss= 0.000108563356, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1330/3333, training loss= 0.00010725154, training acc= 100.0%\n",
            "Validation Accuracy 98.36845397949219 ...\n",
            "\n",
            "Epoch 1340/3333, training loss= 0.00010595007, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1350/3333, training loss= 0.00010473882, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1360/3333, training loss= 0.00010341553, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1370/3333, training loss= 0.00010219095, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1380/3333, training loss= 0.000100983125, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1390/3333, training loss= 9.982039e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1400/3333, training loss= 9.859241e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1410/3333, training loss= 9.734954e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1420/3333, training loss= 9.620046e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1430/3333, training loss= 9.504545e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1440/3333, training loss= 9.389137e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1450/3333, training loss= 9.282115e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1460/3333, training loss= 9.1678805e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1470/3333, training loss= 9.056312e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1480/3333, training loss= 8.94787e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1490/3333, training loss= 8.840796e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1500/3333, training loss= 8.735386e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 1510/3333, training loss= 8.633338e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1520/3333, training loss= 8.528077e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1530/3333, training loss= 8.426603e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1540/3333, training loss= 8.3280815e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1550/3333, training loss= 8.228981e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1560/3333, training loss= 8.131263e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1570/3333, training loss= 8.0355894e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1580/3333, training loss= 7.9390695e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1590/3333, training loss= 7.840878e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1600/3333, training loss= 7.7478064e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1610/3333, training loss= 7.6561075e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1620/3333, training loss= 7.562213e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1630/3333, training loss= 7.470964e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1640/3333, training loss= 7.382413e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1650/3333, training loss= 7.294104e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1660/3333, training loss= 7.209928e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1670/3333, training loss= 7.1253795e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1680/3333, training loss= 7.0379676e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1690/3333, training loss= 6.952815e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1700/3333, training loss= 6.875268e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1710/3333, training loss= 6.789069e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1720/3333, training loss= 6.708136e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1730/3333, training loss= 6.624896e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1740/3333, training loss= 6.544979e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1750/3333, training loss= 6.468635e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1760/3333, training loss= 6.390898e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1770/3333, training loss= 6.316371e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1780/3333, training loss= 6.237605e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1790/3333, training loss= 6.1625746e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1800/3333, training loss= 6.0874896e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1810/3333, training loss= 6.0146813e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1820/3333, training loss= 5.9438946e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1830/3333, training loss= 5.8724178e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1840/3333, training loss= 5.8027792e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1850/3333, training loss= 5.7356126e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1860/3333, training loss= 5.664928e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1870/3333, training loss= 5.6006364e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1880/3333, training loss= 5.5309334e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1890/3333, training loss= 5.4646738e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1900/3333, training loss= 5.4016185e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1910/3333, training loss= 5.335976e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1920/3333, training loss= 5.2716412e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1930/3333, training loss= 5.2089734e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1940/3333, training loss= 5.1467658e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1950/3333, training loss= 5.090491e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 1960/3333, training loss= 5.0256134e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1970/3333, training loss= 4.9648705e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1980/3333, training loss= 4.9061102e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 1990/3333, training loss= 4.8488317e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2000/3333, training loss= 4.7902e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2010/3333, training loss= 4.7335572e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2020/3333, training loss= 4.6818586e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2030/3333, training loss= 4.6219226e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2040/3333, training loss= 4.568074e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2050/3333, training loss= 4.512434e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2060/3333, training loss= 4.4590815e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2070/3333, training loss= 4.4078646e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2080/3333, training loss= 4.355149e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2090/3333, training loss= 4.3023716e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2100/3333, training loss= 4.2514712e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2110/3333, training loss= 4.2018088e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2120/3333, training loss= 4.1524203e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2130/3333, training loss= 4.1038173e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2140/3333, training loss= 4.0549334e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2150/3333, training loss= 4.0087016e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2160/3333, training loss= 3.9646246e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2170/3333, training loss= 3.914686e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2180/3333, training loss= 3.8722283e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2190/3333, training loss= 3.8262533e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2200/3333, training loss= 3.7770034e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2210/3333, training loss= 3.732006e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2220/3333, training loss= 3.6880603e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2230/3333, training loss= 3.6457575e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2240/3333, training loss= 3.6037636e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2250/3333, training loss= 3.559477e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2260/3333, training loss= 3.5177898e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2270/3333, training loss= 3.4769153e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2280/3333, training loss= 3.436101e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2290/3333, training loss= 3.3969816e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2300/3333, training loss= 3.3559987e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2310/3333, training loss= 3.3185024e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2320/3333, training loss= 3.2774336e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2330/3333, training loss= 3.2393677e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2340/3333, training loss= 3.2014956e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2350/3333, training loss= 3.164068e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2360/3333, training loss= 3.1269996e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2370/3333, training loss= 3.0898496e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2380/3333, training loss= 3.053636e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2390/3333, training loss= 3.0184538e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2400/3333, training loss= 2.9827914e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2410/3333, training loss= 2.949032e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2420/3333, training loss= 2.9133089e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2430/3333, training loss= 2.879823e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2440/3333, training loss= 2.8475824e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2450/3333, training loss= 2.8122435e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2460/3333, training loss= 2.7794575e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2470/3333, training loss= 2.746025e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2480/3333, training loss= 2.7148599e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2490/3333, training loss= 2.6833106e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2500/3333, training loss= 2.651202e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2510/3333, training loss= 2.619834e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2520/3333, training loss= 2.5901509e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2530/3333, training loss= 2.5594705e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2540/3333, training loss= 2.5300815e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2550/3333, training loss= 2.4999787e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2560/3333, training loss= 2.4719486e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2570/3333, training loss= 2.44176e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2580/3333, training loss= 2.4140825e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2590/3333, training loss= 2.3842224e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2600/3333, training loss= 2.3562008e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2610/3333, training loss= 2.3287928e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2620/3333, training loss= 2.3014603e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2630/3333, training loss= 2.2747128e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2640/3333, training loss= 2.248664e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2650/3333, training loss= 2.2219583e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2660/3333, training loss= 2.1962062e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2670/3333, training loss= 2.17065e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.57239532470703 ...\n",
            "\n",
            "Epoch 2680/3333, training loss= 2.1451893e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2690/3333, training loss= 2.1202792e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2700/3333, training loss= 2.0953525e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2710/3333, training loss= 2.0707545e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2720/3333, training loss= 2.0465412e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2730/3333, training loss= 2.0230022e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2740/3333, training loss= 1.9986886e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2750/3333, training loss= 1.9756259e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2760/3333, training loss= 1.9520603e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2770/3333, training loss= 1.9296374e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2780/3333, training loss= 1.906599e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2790/3333, training loss= 1.8860204e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2800/3333, training loss= 1.8631703e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2810/3333, training loss= 1.8414648e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2820/3333, training loss= 1.820038e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2830/3333, training loss= 1.7987293e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2840/3333, training loss= 1.7776232e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2850/3333, training loss= 1.756855e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2860/3333, training loss= 1.7363234e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2870/3333, training loss= 1.716652e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2880/3333, training loss= 1.6966476e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2890/3333, training loss= 1.6766164e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 2900/3333, training loss= 1.6570788e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2910/3333, training loss= 1.6380118e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2920/3333, training loss= 1.6188274e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2930/3333, training loss= 1.6001508e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2940/3333, training loss= 1.5816415e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2950/3333, training loss= 1.563193e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2960/3333, training loss= 1.5452468e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2970/3333, training loss= 1.5274903e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2980/3333, training loss= 1.5095017e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 2990/3333, training loss= 1.4923234e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3000/3333, training loss= 1.4757381e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3010/3333, training loss= 1.4600684e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3020/3333, training loss= 1.4425548e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3030/3333, training loss= 1.42479485e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3040/3333, training loss= 1.4083646e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3050/3333, training loss= 1.39176655e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3060/3333, training loss= 1.3754917e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3070/3333, training loss= 1.3599189e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3080/3333, training loss= 1.3440128e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3090/3333, training loss= 1.3282307e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3100/3333, training loss= 1.3129107e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3110/3333, training loss= 1.2980676e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3120/3333, training loss= 1.2831917e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3130/3333, training loss= 1.2695267e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3140/3333, training loss= 1.2544376e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3150/3333, training loss= 1.2389809e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3160/3333, training loss= 1.2249707e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3170/3333, training loss= 1.2105674e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3180/3333, training loss= 1.1965853e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3190/3333, training loss= 1.1828761e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3200/3333, training loss= 1.1691194e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3210/3333, training loss= 1.1558909e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3220/3333, training loss= 1.1425052e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3230/3333, training loss= 1.1292367e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3240/3333, training loss= 1.1168441e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3250/3333, training loss= 1.1044167e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3260/3333, training loss= 1.09141465e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3270/3333, training loss= 1.0790822e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3280/3333, training loss= 1.0662891e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3290/3333, training loss= 1.0538167e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3300/3333, training loss= 1.0416149e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3310/3333, training loss= 1.0298836e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.43643951416016 ...\n",
            "\n",
            "Epoch 3320/3333, training loss= 1.018195e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Epoch 3330/3333, training loss= 1.0060274e-05, training acc= 100.0%\n",
            "Validation Accuracy 98.5044174194336 ...\n",
            "\n",
            "Valid acc= 98.572395 %\n",
            "==================================================\n",
            "W1\n",
            "4\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ctjgqv4OcnxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VMzDOL06cnuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "8a5800db-b03a-4483-86d4-6f3b76496dfa"
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, 3331, 10)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),11,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),11,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oiak3L46dJA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "4efadf0f-c89d-4c22-e5c4-3561de9346f6"
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, 3331, 10)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),3,1))  \n",
        "plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),3,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "i1CaNdeDc_9p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "917f9e10-cab2-4751-c2ae-c5a4dc4b4c53"
      },
      "cell_type": "code",
      "source": [
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.572395\n",
            "187\n",
            "1870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pQiZpMXVc_6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9c95a7f6-f984-49e5-af89-b0c5b0b5d206"
      },
      "cell_type": "code",
      "source": [
        "valid_accuracy_filtered = val_accuracy#savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.572395\n",
            "187\n",
            "1870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AenHvoY8c_3I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MY1cF8ZQb1l2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Now retrain till 2380  epoch with complete data"
      ]
    },
    {
      "metadata": {
        "id": "tk4b9AoviHXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44f072ea-2d60-4750-dc54-3170f5909c48"
      },
      "cell_type": "code",
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5881, 6)\n",
            "(7352, 561)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iGeoQbuFiHTF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 1\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0dSoVofcifpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 2380"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qMrVBWxFiTse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2601
        },
        "outputId": "3627f958-14e7-4e1c-e3d0-ef05224ee60a"
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 100000\n",
        "batch_size = 4112\n",
        "BATCH_SIZE = batch_size\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "###\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "epoch_track = []\n",
        "###\n",
        "learning_rate = 0.0001\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "#############\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for i in range(EPOCHS):\n",
        "      X_train, y_train = shuffle(combined_train_valid, combined_train_valid_label)\n",
        "      \n",
        "      for step in range(0, total_steps_for_one_pass):\n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "            step = 0\n",
        "          else:\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "          sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "      if i % plot_every == 0:\n",
        "          train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: X_train,Y: y_train})\n",
        "          train_accuracy.append(train_acc)\n",
        "          print(\"Epoch \" + str(i) + '/' + str(EPOCHS) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "          train_losses.append(train_loss)\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "          val_accuracy.append(validation_accuracy)\n",
        "          if step%plot_every == 0:\n",
        "            print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "    saver.save(sess, './HArFullBest')\n",
        "    G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2380, training loss= 0.030643174, training acc= 99.57829117774963%\n",
            "Validation Accuracy 97.89258575439453 ...\n",
            "\n",
            "Epoch 50/2380, training loss= 0.0019882785, training acc= 99.94558691978455%\n",
            "Validation Accuracy 99.72808074951172 ...\n",
            "\n",
            "Epoch 100/2380, training loss= 0.0013818503, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 150/2380, training loss= 0.0011214225, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 200/2380, training loss= 0.0009475632, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 250/2380, training loss= 0.00081777514, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 300/2380, training loss= 0.0007162738, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 350/2380, training loss= 0.0006325069, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 400/2380, training loss= 0.00056383613, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 450/2380, training loss= 0.00050508307, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 500/2380, training loss= 0.00045526845, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 550/2380, training loss= 0.0004117013, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 600/2380, training loss= 0.00037383803, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 650/2380, training loss= 0.00034031773, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 700/2380, training loss= 0.00031051238, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 750/2380, training loss= 0.0002839665, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 800/2380, training loss= 0.0002603741, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 850/2380, training loss= 0.00023923027, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 900/2380, training loss= 0.00022013026, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 950/2380, training loss= 0.00020278498, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1000/2380, training loss= 0.0001871578, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1050/2380, training loss= 0.00017284915, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1100/2380, training loss= 0.0001599515, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1150/2380, training loss= 0.00014808912, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1200/2380, training loss= 0.00013728706, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1250/2380, training loss= 0.00012741137, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1300/2380, training loss= 0.00011833787, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1350/2380, training loss= 0.00011001909, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1400/2380, training loss= 0.000102371145, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1450/2380, training loss= 9.5366726e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1500/2380, training loss= 8.876123e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1550/2380, training loss= 8.272686e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1600/2380, training loss= 7.7191056e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1650/2380, training loss= 7.201449e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1700/2380, training loss= 6.72462e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1750/2380, training loss= 6.2830135e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1800/2380, training loss= 5.874811e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1850/2380, training loss= 5.494687e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1900/2380, training loss= 5.1406834e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 1950/2380, training loss= 4.8126207e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2000/2380, training loss= 4.508106e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2050/2380, training loss= 4.2239062e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2100/2380, training loss= 3.959474e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2150/2380, training loss= 3.7132104e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2200/2380, training loss= 3.4841516e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2250/2380, training loss= 3.2698303e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2300/2380, training loss= 3.0691965e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Epoch 2350/2380, training loss= 2.8822586e-05, training acc= 100.0%\n",
            "Validation Accuracy 100.0 ...\n",
            "\n",
            "Valid acc= 100.0 %\n",
            "==================================================\n",
            "W1\n",
            "4\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w2mxHqJHiTqL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cb543f1a-f271-4a7a-84a9-549a7b6d66ee"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './HArFullBest')\n",
        "    train_accuracy = sess.run(accuracy*100, feed_dict={X: X_train,Y: y_train})\n",
        "    print(\"Train acc=\",str(train_accuracy), \"%\")\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./HArFullBest\n",
            "Train acc= 100.0 %\n",
            "ValidValid acc= 100.0 %\n",
            "Test acc= 95.01188 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gFeVzG-_iTnA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zbc1-WviiTkI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "juudSyAz578t"
      },
      "cell_type": "markdown",
      "source": [
        "## Best Tuned, Use W1 = 4, W2 =2, W3 = 1 from best validation accuracy found below"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W5Fa3AIQ5n8N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [374]\n",
        "num_steps = 100000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 50\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letter1')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wwY5Bt2EM3Z8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kwd9EKfLM3Z9",
        "colab_type": "code",
        "outputId": "82535c54-6378-4f17-f5b2-987d3de0fa2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),51,1))  \n",
        "plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),51,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEYCAYAAAA06gPTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MpHiEL6VM3aB",
        "colab_type": "code",
        "outputId": "2d03f9be-d0d6-4a16-aecf-a242575ce7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),51,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.64704\n",
            "485\n",
            "24250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_l2RRE0M3aE",
        "colab_type": "code",
        "outputId": "8ad5cca4-e098-4fa4-bd62-f5f537063401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_label_one_hot.shape)\n",
        "print(train_valid_combined.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5881, 6)\n",
            "(7352, 561)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HaKv7GnsM3aF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 100\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRpkJTtqM3aJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now retrain on this appended test data till 24300 steps"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Uifa_UHiM3aK",
        "colab_type": "code",
        "outputId": "d8ba0e2b-73ee-415a-c457-940391c94d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8432
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 24300\n",
        "# num_steps = 20000\n",
        "\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 50\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 4\n",
        "wLoss2 = 2\n",
        "wLoss3 = 1\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            \n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "    \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './Pendigit')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 0.45379114, training acc total= 93.14671754837036%\n",
            "step 50, training loss Total= 0.039833248, training acc total= 99.64147806167603%\n",
            "step 100, training loss Total= 0.045330588, training acc total= 99.3381142616272%\n",
            "step 150, training loss Total= 0.019238897, training acc total= 99.79315996170044%\n",
            "step 200, training loss Total= 0.013733287, training acc total= 99.86210465431213%\n",
            "step 250, training loss Total= 0.021557797, training acc total= 99.7380018234253%\n",
            "step 300, training loss Total= 0.15683196, training acc total= 98.17981123924255%\n",
            "step 350, training loss Total= 0.016487077, training acc total= 99.86210465431213%\n",
            "step 400, training loss Total= 0.04703603, training acc total= 99.32432174682617%\n",
            "step 450, training loss Total= 0.01743794, training acc total= 99.82073903083801%\n",
            "step 500, training loss Total= 0.009342014, training acc total= 99.91726279258728%\n",
            "step 550, training loss Total= 0.014104057, training acc total= 99.94484186172485%\n",
            "step 600, training loss Total= 0.056876045, training acc total= 99.46221709251404%\n",
            "step 650, training loss Total= 0.023242952, training acc total= 99.75179433822632%\n",
            "step 700, training loss Total= 0.039095264, training acc total= 99.64147806167603%\n",
            "step 750, training loss Total= 0.01313867, training acc total= 99.90347623825073%\n",
            "step 800, training loss Total= 0.0052991095, training acc total= 99.97242093086243%\n",
            "step 850, training loss Total= 0.0073110424, training acc total= 99.94484186172485%\n",
            "step 900, training loss Total= 0.0054948954, training acc total= 100.0%\n",
            "step 950, training loss Total= 0.0026818907, training acc total= 100.0%\n",
            "step 1000, training loss Total= 0.005416252, training acc total= 99.95863437652588%\n",
            "step 1050, training loss Total= 0.0029244383, training acc total= 99.98621344566345%\n",
            "step 1100, training loss Total= 0.009015584, training acc total= 99.91726279258728%\n",
            "step 1150, training loss Total= 0.0047110305, training acc total= 99.97242093086243%\n",
            "step 1200, training loss Total= 0.0025466764, training acc total= 100.0%\n",
            "step 1250, training loss Total= 0.011902557, training acc total= 99.90347623825073%\n",
            "step 1300, training loss Total= 0.0025260278, training acc total= 100.0%\n",
            "step 1350, training loss Total= 0.02453232, training acc total= 99.82073903083801%\n",
            "step 1400, training loss Total= 0.01409426, training acc total= 99.82073903083801%\n",
            "step 1450, training loss Total= 0.023859076, training acc total= 99.80695247650146%\n",
            "step 1500, training loss Total= 0.03329613, training acc total= 99.6690571308136%\n",
            "step 1550, training loss Total= 0.009649995, training acc total= 99.86210465431213%\n",
            "step 1600, training loss Total= 0.003689609, training acc total= 99.98621344566345%\n",
            "step 1650, training loss Total= 0.0005480611, training acc total= 100.0%\n",
            "step 1700, training loss Total= 0.0006046851, training acc total= 100.0%\n",
            "step 1750, training loss Total= 0.002250957, training acc total= 100.0%\n",
            "step 1800, training loss Total= 0.0011101604, training acc total= 99.98621344566345%\n",
            "step 1850, training loss Total= 0.000708361, training acc total= 99.98621344566345%\n",
            "step 1900, training loss Total= 0.00043114158, training acc total= 99.98621344566345%\n",
            "step 1950, training loss Total= 0.00029356795, training acc total= 99.98621344566345%\n",
            "step 2000, training loss Total= 0.0003990697, training acc total= 100.0%\n",
            "step 2050, training loss Total= 0.0002397307, training acc total= 100.0%\n",
            "step 2100, training loss Total= 0.0001829968, training acc total= 100.0%\n",
            "step 2150, training loss Total= 0.00016412513, training acc total= 100.0%\n",
            "step 2200, training loss Total= 0.00016021628, training acc total= 100.0%\n",
            "step 2250, training loss Total= 0.00015052022, training acc total= 100.0%\n",
            "step 2300, training loss Total= 0.00014221712, training acc total= 100.0%\n",
            "step 2350, training loss Total= 0.00013628391, training acc total= 100.0%\n",
            "step 2400, training loss Total= 0.0001313389, training acc total= 100.0%\n",
            "step 2450, training loss Total= 0.0001279928, training acc total= 100.0%\n",
            "step 2500, training loss Total= 0.00012342617, training acc total= 100.0%\n",
            "step 2550, training loss Total= 0.00011975322, training acc total= 100.0%\n",
            "step 2600, training loss Total= 0.00011516353, training acc total= 100.0%\n",
            "step 2650, training loss Total= 0.000115180126, training acc total= 100.0%\n",
            "step 2700, training loss Total= 0.00010938619, training acc total= 100.0%\n",
            "step 2750, training loss Total= 0.000107229935, training acc total= 100.0%\n",
            "step 2800, training loss Total= 0.00010414702, training acc total= 100.0%\n",
            "step 2850, training loss Total= 0.00010170599, training acc total= 100.0%\n",
            "step 2900, training loss Total= 9.9578305e-05, training acc total= 100.0%\n",
            "step 2950, training loss Total= 9.720049e-05, training acc total= 100.0%\n",
            "step 3000, training loss Total= 9.5185576e-05, training acc total= 100.0%\n",
            "step 3050, training loss Total= 9.3388655e-05, training acc total= 100.0%\n",
            "step 3100, training loss Total= 9.1292364e-05, training acc total= 100.0%\n",
            "step 3150, training loss Total= 9.0570175e-05, training acc total= 100.0%\n",
            "step 3200, training loss Total= 8.810865e-05, training acc total= 100.0%\n",
            "step 3250, training loss Total= 8.655106e-05, training acc total= 100.0%\n",
            "step 3300, training loss Total= 8.511055e-05, training acc total= 100.0%\n",
            "step 3350, training loss Total= 8.30821e-05, training acc total= 100.0%\n",
            "step 3400, training loss Total= 8.2190854e-05, training acc total= 100.0%\n",
            "step 3450, training loss Total= 7.991048e-05, training acc total= 100.0%\n",
            "step 3500, training loss Total= 7.9128265e-05, training acc total= 100.0%\n",
            "step 3550, training loss Total= 7.738369e-05, training acc total= 100.0%\n",
            "step 3600, training loss Total= 7.606571e-05, training acc total= 100.0%\n",
            "step 3650, training loss Total= 7.4599535e-05, training acc total= 100.0%\n",
            "step 3700, training loss Total= 7.394822e-05, training acc total= 100.0%\n",
            "step 3750, training loss Total= 7.243282e-05, training acc total= 100.0%\n",
            "step 3800, training loss Total= 7.1066104e-05, training acc total= 100.0%\n",
            "step 3850, training loss Total= 7.007496e-05, training acc total= 100.0%\n",
            "step 3900, training loss Total= 6.9149006e-05, training acc total= 100.0%\n",
            "step 3950, training loss Total= 6.789845e-05, training acc total= 100.0%\n",
            "step 4000, training loss Total= 6.752289e-05, training acc total= 100.0%\n",
            "step 4050, training loss Total= 6.586513e-05, training acc total= 100.0%\n",
            "step 4100, training loss Total= 6.472743e-05, training acc total= 100.0%\n",
            "step 4150, training loss Total= 6.4207445e-05, training acc total= 100.0%\n",
            "step 4200, training loss Total= 6.291922e-05, training acc total= 100.0%\n",
            "step 4250, training loss Total= 6.2562474e-05, training acc total= 100.0%\n",
            "step 4300, training loss Total= 6.151337e-05, training acc total= 100.0%\n",
            "step 4350, training loss Total= 6.0053877e-05, training acc total= 100.0%\n",
            "step 4400, training loss Total= 5.98447e-05, training acc total= 100.0%\n",
            "step 4450, training loss Total= 5.832744e-05, training acc total= 100.0%\n",
            "step 4500, training loss Total= 5.7690355e-05, training acc total= 100.0%\n",
            "step 4550, training loss Total= 5.6781522e-05, training acc total= 100.0%\n",
            "step 4600, training loss Total= 5.579446e-05, training acc total= 100.0%\n",
            "step 4650, training loss Total= 5.5062155e-05, training acc total= 100.0%\n",
            "step 4700, training loss Total= 5.510753e-05, training acc total= 100.0%\n",
            "step 4750, training loss Total= 5.3011812e-05, training acc total= 100.0%\n",
            "step 4800, training loss Total= 5.2269887e-05, training acc total= 100.0%\n",
            "step 4850, training loss Total= 5.1641724e-05, training acc total= 100.0%\n",
            "step 4900, training loss Total= 5.0703253e-05, training acc total= 100.0%\n",
            "step 4950, training loss Total= 5.019182e-05, training acc total= 100.0%\n",
            "step 5000, training loss Total= 5.0755316e-05, training acc total= 100.0%\n",
            "step 5050, training loss Total= 4.9589915e-05, training acc total= 100.0%\n",
            "step 5100, training loss Total= 4.7938887e-05, training acc total= 100.0%\n",
            "step 5150, training loss Total= 4.7407844e-05, training acc total= 100.0%\n",
            "step 5200, training loss Total= 4.6303157e-05, training acc total= 100.0%\n",
            "step 5250, training loss Total= 4.5708e-05, training acc total= 100.0%\n",
            "step 5300, training loss Total= 4.47868e-05, training acc total= 100.0%\n",
            "step 5350, training loss Total= 4.4157092e-05, training acc total= 100.0%\n",
            "step 5400, training loss Total= 4.3727534e-05, training acc total= 100.0%\n",
            "step 5450, training loss Total= 4.2848886e-05, training acc total= 100.0%\n",
            "step 5500, training loss Total= 4.2399846e-05, training acc total= 100.0%\n",
            "step 5550, training loss Total= 4.15261e-05, training acc total= 100.0%\n",
            "step 5600, training loss Total= 4.097614e-05, training acc total= 100.0%\n",
            "step 5650, training loss Total= 4.076816e-05, training acc total= 100.0%\n",
            "step 5700, training loss Total= 3.970181e-05, training acc total= 100.0%\n",
            "step 5750, training loss Total= 3.933144e-05, training acc total= 100.0%\n",
            "step 5800, training loss Total= 3.898717e-05, training acc total= 100.0%\n",
            "step 5850, training loss Total= 3.7689042e-05, training acc total= 100.0%\n",
            "step 5900, training loss Total= 3.6948193e-05, training acc total= 100.0%\n",
            "step 5950, training loss Total= 3.6885023e-05, training acc total= 100.0%\n",
            "step 6000, training loss Total= 3.5781293e-05, training acc total= 100.0%\n",
            "step 6050, training loss Total= 3.5292782e-05, training acc total= 100.0%\n",
            "step 6100, training loss Total= 3.5001445e-05, training acc total= 100.0%\n",
            "step 6150, training loss Total= 3.4707784e-05, training acc total= 100.0%\n",
            "step 6200, training loss Total= 3.333456e-05, training acc total= 100.0%\n",
            "step 6250, training loss Total= 3.2890694e-05, training acc total= 100.0%\n",
            "step 6300, training loss Total= 3.268921e-05, training acc total= 100.0%\n",
            "step 6350, training loss Total= 3.1813724e-05, training acc total= 100.0%\n",
            "step 6400, training loss Total= 3.1175947e-05, training acc total= 100.0%\n",
            "step 6450, training loss Total= 3.06217e-05, training acc total= 100.0%\n",
            "step 6500, training loss Total= 2.9924515e-05, training acc total= 100.0%\n",
            "step 6550, training loss Total= 2.9368362e-05, training acc total= 100.0%\n",
            "step 6600, training loss Total= 2.9557104e-05, training acc total= 100.0%\n",
            "step 6650, training loss Total= 2.8611234e-05, training acc total= 100.0%\n",
            "step 6700, training loss Total= 2.7806207e-05, training acc total= 100.0%\n",
            "step 6750, training loss Total= 2.8191218e-05, training acc total= 100.0%\n",
            "step 6800, training loss Total= 2.6764219e-05, training acc total= 100.0%\n",
            "step 6850, training loss Total= 2.6985621e-05, training acc total= 100.0%\n",
            "step 6900, training loss Total= 2.5748674e-05, training acc total= 100.0%\n",
            "step 6950, training loss Total= 2.5859163e-05, training acc total= 100.0%\n",
            "step 7000, training loss Total= 2.4881081e-05, training acc total= 100.0%\n",
            "step 7050, training loss Total= 2.4454004e-05, training acc total= 100.0%\n",
            "step 7100, training loss Total= 2.4397496e-05, training acc total= 100.0%\n",
            "step 7150, training loss Total= 2.3464538e-05, training acc total= 100.0%\n",
            "step 7200, training loss Total= 2.3243449e-05, training acc total= 100.0%\n",
            "step 7250, training loss Total= 2.2654332e-05, training acc total= 100.0%\n",
            "step 7300, training loss Total= 2.2294273e-05, training acc total= 100.0%\n",
            "step 7350, training loss Total= 2.1747077e-05, training acc total= 100.0%\n",
            "step 7400, training loss Total= 2.1405414e-05, training acc total= 100.0%\n",
            "step 7450, training loss Total= 2.1371805e-05, training acc total= 100.0%\n",
            "step 7500, training loss Total= 2.0714097e-05, training acc total= 100.0%\n",
            "step 7550, training loss Total= 2.0047093e-05, training acc total= 100.0%\n",
            "step 7600, training loss Total= 1.9721607e-05, training acc total= 100.0%\n",
            "step 7650, training loss Total= 1.9668209e-05, training acc total= 100.0%\n",
            "step 7700, training loss Total= 1.9357909e-05, training acc total= 100.0%\n",
            "step 7750, training loss Total= 1.8505072e-05, training acc total= 100.0%\n",
            "step 7800, training loss Total= 1.8325072e-05, training acc total= 100.0%\n",
            "step 7850, training loss Total= 1.7988601e-05, training acc total= 100.0%\n",
            "step 7900, training loss Total= 1.7382707e-05, training acc total= 100.0%\n",
            "step 7950, training loss Total= 1.7103308e-05, training acc total= 100.0%\n",
            "step 8000, training loss Total= 1.676944e-05, training acc total= 100.0%\n",
            "step 8050, training loss Total= 1.6405153e-05, training acc total= 100.0%\n",
            "step 8100, training loss Total= 1.6218299e-05, training acc total= 100.0%\n",
            "step 8150, training loss Total= 1.5685093e-05, training acc total= 100.0%\n",
            "step 8200, training loss Total= 1.5637701e-05, training acc total= 100.0%\n",
            "step 8250, training loss Total= 1.5384174e-05, training acc total= 100.0%\n",
            "step 8300, training loss Total= 1.5263153e-05, training acc total= 100.0%\n",
            "step 8350, training loss Total= 1.4749183e-05, training acc total= 100.0%\n",
            "step 8400, training loss Total= 1.4942148e-05, training acc total= 100.0%\n",
            "step 8450, training loss Total= 1.3973641e-05, training acc total= 100.0%\n",
            "step 8500, training loss Total= 1.5342941e-05, training acc total= 100.0%\n",
            "step 8550, training loss Total= 1.352159e-05, training acc total= 100.0%\n",
            "step 8600, training loss Total= 1.3141211e-05, training acc total= 100.0%\n",
            "step 8650, training loss Total= 1.2816561e-05, training acc total= 100.0%\n",
            "step 8700, training loss Total= 1.2515919e-05, training acc total= 100.0%\n",
            "step 8750, training loss Total= 1.2235865e-05, training acc total= 100.0%\n",
            "step 8800, training loss Total= 1.194812e-05, training acc total= 100.0%\n",
            "step 8850, training loss Total= 1.1650202e-05, training acc total= 100.0%\n",
            "step 8900, training loss Total= 1.18395465e-05, training acc total= 100.0%\n",
            "step 8950, training loss Total= 1.1626804e-05, training acc total= 100.0%\n",
            "step 9000, training loss Total= 1.09505445e-05, training acc total= 100.0%\n",
            "step 9050, training loss Total= 1.0693775e-05, training acc total= 100.0%\n",
            "step 9100, training loss Total= 1.0483288e-05, training acc total= 100.0%\n",
            "step 9150, training loss Total= 1.0218528e-05, training acc total= 100.0%\n",
            "step 9200, training loss Total= 1.0311115e-05, training acc total= 100.0%\n",
            "step 9250, training loss Total= 1.0391344e-05, training acc total= 100.0%\n",
            "step 9300, training loss Total= 9.610909e-06, training acc total= 100.0%\n",
            "step 9350, training loss Total= 9.3115705e-06, training acc total= 100.0%\n",
            "step 9400, training loss Total= 9.170817e-06, training acc total= 100.0%\n",
            "step 9450, training loss Total= 8.87041e-06, training acc total= 100.0%\n",
            "step 9500, training loss Total= 8.703654e-06, training acc total= 100.0%\n",
            "step 9550, training loss Total= 8.5080765e-06, training acc total= 100.0%\n",
            "step 9600, training loss Total= 8.317578e-06, training acc total= 100.0%\n",
            "step 9650, training loss Total= 8.11799e-06, training acc total= 100.0%\n",
            "step 9700, training loss Total= 7.88519e-06, training acc total= 100.0%\n",
            "step 9750, training loss Total= 7.749754e-06, training acc total= 100.0%\n",
            "step 9800, training loss Total= 7.5953894e-06, training acc total= 100.0%\n",
            "step 9850, training loss Total= 7.3588785e-06, training acc total= 100.0%\n",
            "step 9900, training loss Total= 7.3093056e-06, training acc total= 100.0%\n",
            "step 9950, training loss Total= 7.02444e-06, training acc total= 100.0%\n",
            "step 10000, training loss Total= 6.8462446e-06, training acc total= 100.0%\n",
            "step 10050, training loss Total= 6.649202e-06, training acc total= 100.0%\n",
            "step 10100, training loss Total= 6.5015815e-06, training acc total= 100.0%\n",
            "step 10150, training loss Total= 6.4178876e-06, training acc total= 100.0%\n",
            "step 10200, training loss Total= 6.4071637e-06, training acc total= 100.0%\n",
            "step 10250, training loss Total= 6.3303687e-06, training acc total= 100.0%\n",
            "step 10300, training loss Total= 5.9762883e-06, training acc total= 100.0%\n",
            "step 10350, training loss Total= 6.5979016e-06, training acc total= 100.0%\n",
            "step 10400, training loss Total= 6.0262655e-06, training acc total= 100.0%\n",
            "step 10450, training loss Total= 5.6011913e-06, training acc total= 100.0%\n",
            "step 10500, training loss Total= 5.4835136e-06, training acc total= 100.0%\n",
            "step 10550, training loss Total= 5.374652e-06, training acc total= 100.0%\n",
            "step 10600, training loss Total= 5.1238726e-06, training acc total= 100.0%\n",
            "step 10650, training loss Total= 4.988756e-06, training acc total= 100.0%\n",
            "step 10700, training loss Total= 5.152259e-06, training acc total= 100.0%\n",
            "step 10750, training loss Total= 4.868415e-06, training acc total= 100.0%\n",
            "step 10800, training loss Total= 4.6311525e-06, training acc total= 100.0%\n",
            "step 10850, training loss Total= 4.490116e-06, training acc total= 100.0%\n",
            "step 10900, training loss Total= 4.3844657e-06, training acc total= 100.0%\n",
            "step 10950, training loss Total= 4.347875e-06, training acc total= 100.0%\n",
            "step 11000, training loss Total= 4.3009345e-06, training acc total= 100.0%\n",
            "step 11050, training loss Total= 4.264303e-06, training acc total= 100.0%\n",
            "step 11100, training loss Total= 4.0137693e-06, training acc total= 100.0%\n",
            "step 11150, training loss Total= 3.863273e-06, training acc total= 100.0%\n",
            "step 11200, training loss Total= 3.8003948e-06, training acc total= 100.0%\n",
            "step 11250, training loss Total= 3.825282e-06, training acc total= 100.0%\n",
            "step 11300, training loss Total= 3.6556785e-06, training acc total= 100.0%\n",
            "step 11350, training loss Total= 3.543266e-06, training acc total= 100.0%\n",
            "step 11400, training loss Total= 3.4455707e-06, training acc total= 100.0%\n",
            "step 11450, training loss Total= 3.3386596e-06, training acc total= 100.0%\n",
            "step 11500, training loss Total= 3.3748452e-06, training acc total= 100.0%\n",
            "step 11550, training loss Total= 3.1914726e-06, training acc total= 100.0%\n",
            "step 11600, training loss Total= 3.084842e-06, training acc total= 100.0%\n",
            "step 11650, training loss Total= 2.993544e-06, training acc total= 100.0%\n",
            "step 11700, training loss Total= 2.931459e-06, training acc total= 100.0%\n",
            "step 11750, training loss Total= 2.865205e-06, training acc total= 100.0%\n",
            "step 11800, training loss Total= 2.795469e-06, training acc total= 100.0%\n",
            "step 11850, training loss Total= 2.874802e-06, training acc total= 100.0%\n",
            "step 11900, training loss Total= 1.0209057, training acc total= 94.60838437080383%\n",
            "step 11950, training loss Total= 0.07255421, training acc total= 99.37947988510132%\n",
            "step 12000, training loss Total= 0.0339027, training acc total= 99.86210465431213%\n",
            "step 12050, training loss Total= 0.014941098, training acc total= 99.97242093086243%\n",
            "step 12100, training loss Total= 0.021021731, training acc total= 99.94484186172485%\n",
            "step 12150, training loss Total= 0.0063558845, training acc total= 99.97242093086243%\n",
            "step 12200, training loss Total= 0.0075750193, training acc total= 100.0%\n",
            "step 12250, training loss Total= 0.005658201, training acc total= 99.98621344566345%\n",
            "step 12300, training loss Total= 0.0025600367, training acc total= 100.0%\n",
            "step 12350, training loss Total= 0.01002537, training acc total= 99.94484186172485%\n",
            "step 12400, training loss Total= 0.0026108145, training acc total= 100.0%\n",
            "step 12450, training loss Total= 0.0064419555, training acc total= 100.0%\n",
            "step 12500, training loss Total= 0.0029203158, training acc total= 100.0%\n",
            "step 12550, training loss Total= 0.002632146, training acc total= 100.0%\n",
            "step 12600, training loss Total= 0.00075261656, training acc total= 100.0%\n",
            "step 12650, training loss Total= 0.000614577, training acc total= 100.0%\n",
            "step 12700, training loss Total= 0.00038471568, training acc total= 100.0%\n",
            "step 12750, training loss Total= 0.0002161647, training acc total= 100.0%\n",
            "step 12800, training loss Total= 0.00012398882, training acc total= 100.0%\n",
            "step 12850, training loss Total= 0.000118790806, training acc total= 100.0%\n",
            "step 12900, training loss Total= 9.826971e-05, training acc total= 100.0%\n",
            "step 12950, training loss Total= 8.907376e-05, training acc total= 100.0%\n",
            "step 13000, training loss Total= 8.240566e-05, training acc total= 100.0%\n",
            "step 13050, training loss Total= 7.578769e-05, training acc total= 100.0%\n",
            "step 13100, training loss Total= 7.1960305e-05, training acc total= 100.0%\n",
            "step 13150, training loss Total= 6.774983e-05, training acc total= 100.0%\n",
            "step 13200, training loss Total= 6.53275e-05, training acc total= 100.0%\n",
            "step 13250, training loss Total= 6.2719664e-05, training acc total= 100.0%\n",
            "step 13300, training loss Total= 6.3502426e-05, training acc total= 100.0%\n",
            "step 13350, training loss Total= 5.8850674e-05, training acc total= 100.0%\n",
            "step 13400, training loss Total= 5.8054902e-05, training acc total= 100.0%\n",
            "step 13450, training loss Total= 5.750559e-05, training acc total= 100.0%\n",
            "step 13500, training loss Total= 6.4130785e-05, training acc total= 100.0%\n",
            "step 13550, training loss Total= 5.6682693e-05, training acc total= 100.0%\n",
            "step 13600, training loss Total= 5.308215e-05, training acc total= 100.0%\n",
            "step 13650, training loss Total= 5.2863226e-05, training acc total= 100.0%\n",
            "step 13700, training loss Total= 4.9961112e-05, training acc total= 100.0%\n",
            "step 13750, training loss Total= 4.8936126e-05, training acc total= 100.0%\n",
            "step 13800, training loss Total= 4.7082147e-05, training acc total= 100.0%\n",
            "step 13850, training loss Total= 4.624399e-05, training acc total= 100.0%\n",
            "step 13900, training loss Total= 4.534407e-05, training acc total= 100.0%\n",
            "step 13950, training loss Total= 4.3765842e-05, training acc total= 100.0%\n",
            "step 14000, training loss Total= 4.3111228e-05, training acc total= 100.0%\n",
            "step 14050, training loss Total= 4.7520767e-05, training acc total= 100.0%\n",
            "step 14100, training loss Total= 4.28178e-05, training acc total= 100.0%\n",
            "step 14150, training loss Total= 4.1930125e-05, training acc total= 100.0%\n",
            "step 14200, training loss Total= 4.179911e-05, training acc total= 100.0%\n",
            "step 14250, training loss Total= 4.1090072e-05, training acc total= 100.0%\n",
            "step 14300, training loss Total= 3.924191e-05, training acc total= 100.0%\n",
            "step 14350, training loss Total= 3.9495477e-05, training acc total= 100.0%\n",
            "step 14400, training loss Total= 3.9067312e-05, training acc total= 100.0%\n",
            "step 14450, training loss Total= 3.712748e-05, training acc total= 100.0%\n",
            "step 14500, training loss Total= 3.9845294e-05, training acc total= 100.0%\n",
            "step 14550, training loss Total= 3.5955298e-05, training acc total= 100.0%\n",
            "step 14600, training loss Total= 3.5604637e-05, training acc total= 100.0%\n",
            "step 14650, training loss Total= 3.8322854e-05, training acc total= 100.0%\n",
            "step 14700, training loss Total= 3.435951e-05, training acc total= 100.0%\n",
            "step 14750, training loss Total= 3.4393794e-05, training acc total= 100.0%\n",
            "step 14800, training loss Total= 3.3091106e-05, training acc total= 100.0%\n",
            "step 14850, training loss Total= 3.2454176e-05, training acc total= 100.0%\n",
            "step 14900, training loss Total= 3.198538e-05, training acc total= 100.0%\n",
            "step 14950, training loss Total= 3.2053125e-05, training acc total= 100.0%\n",
            "step 15000, training loss Total= 3.1777246e-05, training acc total= 100.0%\n",
            "step 15050, training loss Total= 3.0407202e-05, training acc total= 100.0%\n",
            "step 15100, training loss Total= 2.995752e-05, training acc total= 100.0%\n",
            "step 15150, training loss Total= 3.0806186e-05, training acc total= 100.0%\n",
            "step 15200, training loss Total= 2.9611158e-05, training acc total= 100.0%\n",
            "step 15250, training loss Total= 2.8551924e-05, training acc total= 100.0%\n",
            "step 15300, training loss Total= 2.8678187e-05, training acc total= 100.0%\n",
            "step 15350, training loss Total= 2.8250133e-05, training acc total= 100.0%\n",
            "step 15400, training loss Total= 2.7691269e-05, training acc total= 100.0%\n",
            "step 15450, training loss Total= 2.7365511e-05, training acc total= 100.0%\n",
            "step 15500, training loss Total= 2.687747e-05, training acc total= 100.0%\n",
            "step 15550, training loss Total= 2.6238273e-05, training acc total= 100.0%\n",
            "step 15600, training loss Total= 2.5903539e-05, training acc total= 100.0%\n",
            "step 15650, training loss Total= 2.5482948e-05, training acc total= 100.0%\n",
            "step 15700, training loss Total= 2.487454e-05, training acc total= 100.0%\n",
            "step 15750, training loss Total= 2.4458062e-05, training acc total= 100.0%\n",
            "step 15800, training loss Total= 2.473055e-05, training acc total= 100.0%\n",
            "step 15850, training loss Total= 2.3969742e-05, training acc total= 100.0%\n",
            "step 15900, training loss Total= 2.6466554e-05, training acc total= 100.0%\n",
            "step 15950, training loss Total= 2.834014e-05, training acc total= 100.0%\n",
            "step 16000, training loss Total= 2.6482347e-05, training acc total= 100.0%\n",
            "step 16050, training loss Total= 2.4651712e-05, training acc total= 100.0%\n",
            "step 16100, training loss Total= 2.3973747e-05, training acc total= 100.0%\n",
            "step 16150, training loss Total= 2.3076702e-05, training acc total= 100.0%\n",
            "step 16200, training loss Total= 2.2449334e-05, training acc total= 100.0%\n",
            "step 16250, training loss Total= 2.2098344e-05, training acc total= 100.0%\n",
            "step 16300, training loss Total= 2.1766302e-05, training acc total= 100.0%\n",
            "step 16350, training loss Total= 2.1222e-05, training acc total= 100.0%\n",
            "step 16400, training loss Total= 2.080561e-05, training acc total= 100.0%\n",
            "step 16450, training loss Total= 2.090354e-05, training acc total= 100.0%\n",
            "step 16500, training loss Total= 2.0370742e-05, training acc total= 100.0%\n",
            "step 16550, training loss Total= 2.0760885e-05, training acc total= 100.0%\n",
            "step 16600, training loss Total= 1.9534786e-05, training acc total= 100.0%\n",
            "step 16650, training loss Total= 1.9427054e-05, training acc total= 100.0%\n",
            "step 16700, training loss Total= 1.87044e-05, training acc total= 100.0%\n",
            "step 16750, training loss Total= 1.8716624e-05, training acc total= 100.0%\n",
            "step 16800, training loss Total= 2.2635626e-05, training acc total= 100.0%\n",
            "step 16850, training loss Total= 1.8225313e-05, training acc total= 100.0%\n",
            "step 16900, training loss Total= 1.7550552e-05, training acc total= 100.0%\n",
            "step 16950, training loss Total= 1.7222199e-05, training acc total= 100.0%\n",
            "step 17000, training loss Total= 1.697274e-05, training acc total= 100.0%\n",
            "step 17050, training loss Total= 1.6750691e-05, training acc total= 100.0%\n",
            "step 17100, training loss Total= 1.6436534e-05, training acc total= 100.0%\n",
            "step 17150, training loss Total= 1.598548e-05, training acc total= 100.0%\n",
            "step 17200, training loss Total= 1.5796219e-05, training acc total= 100.0%\n",
            "step 17250, training loss Total= 1.5340629e-05, training acc total= 100.0%\n",
            "step 17300, training loss Total= 1.565426e-05, training acc total= 100.0%\n",
            "step 17350, training loss Total= 1.46872935e-05, training acc total= 100.0%\n",
            "step 17400, training loss Total= 1.4296611e-05, training acc total= 100.0%\n",
            "step 17450, training loss Total= 1.5036277e-05, training acc total= 100.0%\n",
            "step 17500, training loss Total= 1.508462e-05, training acc total= 100.0%\n",
            "step 17550, training loss Total= 1.4147187e-05, training acc total= 100.0%\n",
            "step 17600, training loss Total= 1.3512053e-05, training acc total= 100.0%\n",
            "step 17650, training loss Total= 1.4053218e-05, training acc total= 100.0%\n",
            "step 17700, training loss Total= 1.3120511e-05, training acc total= 100.0%\n",
            "step 17750, training loss Total= 1.3031911e-05, training acc total= 100.0%\n",
            "step 17800, training loss Total= 1.3263974e-05, training acc total= 100.0%\n",
            "step 17850, training loss Total= 1.2188266e-05, training acc total= 100.0%\n",
            "step 17900, training loss Total= 1.2318173e-05, training acc total= 100.0%\n",
            "step 17950, training loss Total= 1.1965285e-05, training acc total= 100.0%\n",
            "step 18000, training loss Total= 1.1512229e-05, training acc total= 100.0%\n",
            "step 18050, training loss Total= 1.1250276e-05, training acc total= 100.0%\n",
            "step 18100, training loss Total= 1.1044826e-05, training acc total= 100.0%\n",
            "step 18150, training loss Total= 1.2330011e-05, training acc total= 100.0%\n",
            "step 18200, training loss Total= 1.0683701e-05, training acc total= 100.0%\n",
            "step 18250, training loss Total= 1.0797374e-05, training acc total= 100.0%\n",
            "step 18300, training loss Total= 1.0438748e-05, training acc total= 100.0%\n",
            "step 18350, training loss Total= 1.00635125e-05, training acc total= 100.0%\n",
            "step 18400, training loss Total= 9.913598e-06, training acc total= 100.0%\n",
            "step 18450, training loss Total= 1.0549147e-05, training acc total= 100.0%\n",
            "step 18500, training loss Total= 1.0018655e-05, training acc total= 100.0%\n",
            "step 18550, training loss Total= 1.0534897e-05, training acc total= 100.0%\n",
            "step 18600, training loss Total= 9.481535e-06, training acc total= 100.0%\n",
            "step 18650, training loss Total= 9.153038e-06, training acc total= 100.0%\n",
            "step 18700, training loss Total= 8.9223395e-06, training acc total= 100.0%\n",
            "step 18750, training loss Total= 8.7094795e-06, training acc total= 100.0%\n",
            "step 18800, training loss Total= 8.681695e-06, training acc total= 100.0%\n",
            "step 18850, training loss Total= 8.363177e-06, training acc total= 100.0%\n",
            "step 18900, training loss Total= 8.277223e-06, training acc total= 100.0%\n",
            "step 18950, training loss Total= 8.2033885e-06, training acc total= 100.0%\n",
            "step 19000, training loss Total= 7.806901e-06, training acc total= 100.0%\n",
            "step 19050, training loss Total= 7.658677e-06, training acc total= 100.0%\n",
            "step 19100, training loss Total= 7.775378e-06, training acc total= 100.0%\n",
            "step 19150, training loss Total= 7.3148403e-06, training acc total= 100.0%\n",
            "step 19200, training loss Total= 7.185485e-06, training acc total= 100.0%\n",
            "step 19250, training loss Total= 7.5392913e-06, training acc total= 100.0%\n",
            "step 19300, training loss Total= 7.0234905e-06, training acc total= 100.0%\n",
            "step 19350, training loss Total= 6.9441194e-06, training acc total= 100.0%\n",
            "step 19400, training loss Total= 6.727451e-06, training acc total= 100.0%\n",
            "step 19450, training loss Total= 6.7591345e-06, training acc total= 100.0%\n",
            "step 19500, training loss Total= 6.681769e-06, training acc total= 100.0%\n",
            "step 19550, training loss Total= 6.309461e-06, training acc total= 100.0%\n",
            "step 19600, training loss Total= 6.2060367e-06, training acc total= 100.0%\n",
            "step 19650, training loss Total= 6.0697666e-06, training acc total= 100.0%\n",
            "step 19700, training loss Total= 5.915979e-06, training acc total= 100.0%\n",
            "step 19750, training loss Total= 5.7332577e-06, training acc total= 100.0%\n",
            "step 19800, training loss Total= 5.637579e-06, training acc total= 100.0%\n",
            "step 19850, training loss Total= 5.9968793e-06, training acc total= 100.0%\n",
            "step 19900, training loss Total= 5.424773e-06, training acc total= 100.0%\n",
            "step 19950, training loss Total= 5.447223e-06, training acc total= 100.0%\n",
            "step 20000, training loss Total= 5.1735146e-06, training acc total= 100.0%\n",
            "step 20050, training loss Total= 5.4999823e-06, training acc total= 100.0%\n",
            "step 20100, training loss Total= 5.0290687e-06, training acc total= 100.0%\n",
            "step 20150, training loss Total= 4.842328e-06, training acc total= 100.0%\n",
            "step 20200, training loss Total= 4.793106e-06, training acc total= 100.0%\n",
            "step 20250, training loss Total= 4.73369e-06, training acc total= 100.0%\n",
            "step 20300, training loss Total= 4.645777e-06, training acc total= 100.0%\n",
            "step 20350, training loss Total= 4.8547076e-06, training acc total= 100.0%\n",
            "step 20400, training loss Total= 4.9739415e-06, training acc total= 100.0%\n",
            "step 20450, training loss Total= 3.5053017, training acc total= 89.68560099601746%\n",
            "step 20500, training loss Total= 0.10172338, training acc total= 99.25537705421448%\n",
            "step 20550, training loss Total= 0.037739296, training acc total= 99.86210465431213%\n",
            "step 20600, training loss Total= 0.018938145, training acc total= 99.94484186172485%\n",
            "step 20650, training loss Total= 0.020598738, training acc total= 99.8896837234497%\n",
            "step 20700, training loss Total= 0.03055688, training acc total= 99.79315996170044%\n",
            "step 20750, training loss Total= 0.007804987, training acc total= 99.95863437652588%\n",
            "step 20800, training loss Total= 0.008381491, training acc total= 99.98621344566345%\n",
            "step 20850, training loss Total= 0.0035855577, training acc total= 100.0%\n",
            "step 20900, training loss Total= 0.0026489256, training acc total= 100.0%\n",
            "step 20950, training loss Total= 0.002648671, training acc total= 100.0%\n",
            "step 21000, training loss Total= 0.0011988437, training acc total= 100.0%\n",
            "step 21050, training loss Total= 0.0006779384, training acc total= 100.0%\n",
            "step 21100, training loss Total= 0.0006692555, training acc total= 100.0%\n",
            "step 21150, training loss Total= 0.00031337776, training acc total= 100.0%\n",
            "step 21200, training loss Total= 0.00023146188, training acc total= 100.0%\n",
            "step 21250, training loss Total= 0.00017637269, training acc total= 100.0%\n",
            "step 21300, training loss Total= 0.00017985937, training acc total= 100.0%\n",
            "step 21350, training loss Total= 0.00014176367, training acc total= 100.0%\n",
            "step 21400, training loss Total= 0.00013669221, training acc total= 100.0%\n",
            "step 21450, training loss Total= 0.00012420192, training acc total= 100.0%\n",
            "step 21500, training loss Total= 0.00012334884, training acc total= 100.0%\n",
            "step 21550, training loss Total= 0.00011904327, training acc total= 100.0%\n",
            "step 21600, training loss Total= 0.00011099148, training acc total= 100.0%\n",
            "step 21650, training loss Total= 0.00010931609, training acc total= 100.0%\n",
            "step 21700, training loss Total= 9.824542e-05, training acc total= 100.0%\n",
            "step 21750, training loss Total= 9.387492e-05, training acc total= 100.0%\n",
            "step 21800, training loss Total= 9.347381e-05, training acc total= 100.0%\n",
            "step 21850, training loss Total= 8.649283e-05, training acc total= 100.0%\n",
            "step 21900, training loss Total= 8.3630344e-05, training acc total= 100.0%\n",
            "step 21950, training loss Total= 8.3775325e-05, training acc total= 100.0%\n",
            "step 22000, training loss Total= 8.0197606e-05, training acc total= 100.0%\n",
            "step 22050, training loss Total= 7.768636e-05, training acc total= 100.0%\n",
            "step 22100, training loss Total= 7.589365e-05, training acc total= 100.0%\n",
            "step 22150, training loss Total= 7.506433e-05, training acc total= 100.0%\n",
            "step 22200, training loss Total= 7.6290264e-05, training acc total= 100.0%\n",
            "step 22250, training loss Total= 7.0420145e-05, training acc total= 100.0%\n",
            "step 22300, training loss Total= 7.1476854e-05, training acc total= 100.0%\n",
            "step 22350, training loss Total= 6.6403634e-05, training acc total= 100.0%\n",
            "step 22400, training loss Total= 6.638282e-05, training acc total= 100.0%\n",
            "step 22450, training loss Total= 6.378655e-05, training acc total= 100.0%\n",
            "step 22500, training loss Total= 6.2599196e-05, training acc total= 100.0%\n",
            "step 22550, training loss Total= 6.110889e-05, training acc total= 100.0%\n",
            "step 22600, training loss Total= 6.026148e-05, training acc total= 100.0%\n",
            "step 22650, training loss Total= 5.981463e-05, training acc total= 100.0%\n",
            "step 22700, training loss Total= 5.8371283e-05, training acc total= 100.0%\n",
            "step 22750, training loss Total= 5.8286798e-05, training acc total= 100.0%\n",
            "step 22800, training loss Total= 5.529193e-05, training acc total= 100.0%\n",
            "step 22850, training loss Total= 5.9883594e-05, training acc total= 100.0%\n",
            "step 22900, training loss Total= 5.393805e-05, training acc total= 100.0%\n",
            "step 22950, training loss Total= 5.3223517e-05, training acc total= 100.0%\n",
            "step 23000, training loss Total= 5.308398e-05, training acc total= 100.0%\n",
            "step 23050, training loss Total= 5.040383e-05, training acc total= 100.0%\n",
            "step 23100, training loss Total= 4.928916e-05, training acc total= 100.0%\n",
            "step 23150, training loss Total= 4.815358e-05, training acc total= 100.0%\n",
            "step 23200, training loss Total= 4.786538e-05, training acc total= 100.0%\n",
            "step 23250, training loss Total= 4.7190108e-05, training acc total= 100.0%\n",
            "step 23300, training loss Total= 4.5908808e-05, training acc total= 100.0%\n",
            "step 23350, training loss Total= 4.485738e-05, training acc total= 100.0%\n",
            "step 23400, training loss Total= 4.4378958e-05, training acc total= 100.0%\n",
            "step 23450, training loss Total= 4.341851e-05, training acc total= 100.0%\n",
            "step 23500, training loss Total= 4.2810032e-05, training acc total= 100.0%\n",
            "step 23550, training loss Total= 4.1852305e-05, training acc total= 100.0%\n",
            "step 23600, training loss Total= 4.5016805e-05, training acc total= 100.0%\n",
            "step 23650, training loss Total= 4.016359e-05, training acc total= 100.0%\n",
            "step 23700, training loss Total= 3.920151e-05, training acc total= 100.0%\n",
            "step 23750, training loss Total= 3.94171e-05, training acc total= 100.0%\n",
            "step 23800, training loss Total= 3.7841815e-05, training acc total= 100.0%\n",
            "step 23850, training loss Total= 3.707498e-05, training acc total= 100.0%\n",
            "step 23900, training loss Total= 3.61458e-05, training acc total= 100.0%\n",
            "step 23950, training loss Total= 3.5822e-05, training acc total= 100.0%\n",
            "step 24000, training loss Total= 4.2347845e-05, training acc total= 100.0%\n",
            "step 24050, training loss Total= 3.7062808e-05, training acc total= 100.0%\n",
            "step 24100, training loss Total= 3.4290773e-05, training acc total= 100.0%\n",
            "step 24150, training loss Total= 3.290595e-05, training acc total= 100.0%\n",
            "step 24200, training loss Total= 3.183751e-05, training acc total= 100.0%\n",
            "step 24250, training loss Total= 3.128255e-05, training acc total= 100.0%\n",
            "ValidValid acc= 99.93202 %\n",
            "ValidTest acc= 99.0 %\n",
            "==================================================\n",
            "W1\n",
            "4\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ft97oy5cM3aN",
        "colab_type": "code",
        "outputId": "c0b2db3c-1b5b-463d-c3ec-ba640046fa73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./Pendigit\n",
            "ValidValid acc= 99.93202 %\n",
            "Test acc= 94.876144 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CWblrxpgM3aR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ihtQRjvnM3aV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LUJzvaHZ6B3v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "best_weights = {'G_W1': G_W1np, 'G_b1': G_b1np,'G_W2': G_W2np, 'G_b2': G_b2np}\n",
        "scipy.io.savemat('HarFullDataset03212019_Adam', best_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9WWYbkum6Kl4"
      },
      "cell_type": "markdown",
      "source": [
        "## Verify handover works"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-2ER5pNw6JCz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "x = loadmat('HarFullDataset03212019_Adam.mat')\n",
        "G_W1np, G_b1np, G_W2np, G_b2np= x['G_W1'],x['G_b1'], x['G_W2'],x['G_b2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n1lIoTcq6N43",
        "outputId": "752fc367-a7c3-4399-af51-abc1718ffe58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1np), G_b1np)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2np) + G_b2np\n",
        "    layer_outputs.append(out_layer)\n",
        "    return layer_outputs\n",
        "\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"Valid acc=\",str(validation_accuracy), \"%\")\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid acc= 98.64038 %\n",
            "Test acc= 95.38514 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2BZiy1Lgx0b4",
        "colab_type": "code",
        "outputId": "c50c4a28-0265-45ac-d260-812a62ee940a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i-MLbTOJQFQJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning by splitting valid into two sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-BkroR_XQFQK",
        "outputId": "d0e538bd-2766-47d7-bebb-c4691f6506c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278830
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,5):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for step in range(0, num_steps):\n",
        "                batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "                if step % plot_every == 0:\n",
        "                    train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                    print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                    train_losses.append(train_loss)\n",
        "                    validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                    if step%plot_every == 0:\n",
        "                      print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                      print()\n",
        "                      if (validation_accuracy >= best_accuracy_valid):\n",
        "                        best_accuracy_valid = validation_accuracy\n",
        "                        saver.save(sess, './statlog_letter')\n",
        "                        G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 1.9857837, training acc= 88.99999856948853%\n",
            "Validation Accuracy valid 87.5999984741211 ...\n",
            "\n",
            "step 100, training loss= 0.008144151, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.0006294729, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0005400359, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 400, training loss= 0.1527065, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 500, training loss= 0.0013683734, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00021194252, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00032862485, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00025341622, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.00028031622, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.00020475077, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1100, training loss= 0.0003020033, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00024354778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00014706065, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00029177137, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.0001350425, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00016606697, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00018623672, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00015216254, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1900, training loss= 0.00011072023, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 0.00014188612, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2100, training loss= 0.00023836568, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2200, training loss= 0.0001355805, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 0.0001233557, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2400, training loss= 0.00016521299, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2500, training loss= 0.00019633351, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 0.00010483772, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2700, training loss= 0.00014303994, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 9.586293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 6.609259e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 9.8155026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 3.3604018e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3200, training loss= 9.2597256e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 6.721567e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 7.687432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 6.780202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 8.004801e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.1782518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.9696853e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 6.810024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 7.636981e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.5683905e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 5.8620117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 4.8458773e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 5.265702e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 8.7179935e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 2.327066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 5.9413127e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.1775235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 1.39963295e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.2185797e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 2.6216587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 2.6288237e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 4.5653866e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.2123731e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 2.3709934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 1.8652794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.2361822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 1.9032594e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.2012822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 1.6528496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.1033039e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 1.5385518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.5541144e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 2.489545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 9.935381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.3722548e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.4826099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 1.3191649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.5937192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.5124231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 9.579236e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.0794279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.2980037e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.1881518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.0636356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 4.5980264e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 6.622366e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 1.09407665e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.1238885e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 7.4111827e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.7718606e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 5.1832344e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 2.6180458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 3.5346616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 6.9588204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 6.3365137e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 6.0044563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 5.809996e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 2.5300678e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 5.2133055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.3530669e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 7.1355425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 5.349093e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 3.9301335e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 2.0649427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 3.6249492e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 3.645543e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 2.8087782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.811128e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 2.698381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 2.818887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 2.8230727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 1.6247938e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 2.3677005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.494359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 1.8569029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 2.545933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 1.9594595e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 1.4409051e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 6.8693646e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.000875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.2531683e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 1.0448554e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 1.5181027e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 1.1676285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11600, training loss= 9.0001987e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 9.393475e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 8.669367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 5.629609e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 9.915129e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 6.344809e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 8.430959e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 7.560755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.3955247e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 5.1885485e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 2.8520526e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 7.706814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 5.3196766e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 5.519351e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 7.3104553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 6.1064213e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 2.6166344e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 3.2424703e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 4.398789e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 3.7252724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 2.2113223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 4.348137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 4.085874e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 3.302084e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 3.1202762e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 2.3454369e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.3543713e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 1.8954229e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 2.3066919e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 3.632889e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 1.8328382e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 1.0132776e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.5331883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 2.3394738e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 2.9802197e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.4156079e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.7911132e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 1.5228956e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.8358172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 1.2308327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 9.477127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 1.296399e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 7.7187906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 1.5169358e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 8.493651e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 5.394215e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 9.5963244e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 8.463851e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 1.2904381e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 1.1980514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 4.172321e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 5.1557972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 9.387722e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.755089e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.9935088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 6.169074e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 2.384185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 6.228681e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 5.2750053e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 4.79817e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 4.2617295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 4.023311e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.0829136e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 3.308056e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 4.2021256e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 3.3378583e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 4.053114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.2351736e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 2.264975e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.2649754e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.2218949e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.1590442e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 2.1457668e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.3113018e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.3113021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 2.4735918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.7285343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.609325e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.0132787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.1026856e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.1324881e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.1622901e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.2814996e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 8.344648e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.1026857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 7.45058e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 6.8545334e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 3.278255e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23600, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23800, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 23900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24100, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24500, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 24900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.08719349, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 28000, training loss= 0.025652321, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28100, training loss= 0.04324808, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28200, training loss= 0.0004310665, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 2.643979e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 1.3230393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28500, training loss= 0.007661752, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 6.094262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 8.180307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 2.5535144e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 2.176015e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 1.8676748e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 1.7169636e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 7.167124e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 8.642062e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 2.030267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 2.1825708e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 2.7748385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 5.291539e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 1.22399315e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 1.7870418e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.7662272, training acc= 81.99999928474426%\n",
            "Validation Accuracy valid 86.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.008894306, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.001817639, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.01971873, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 400, training loss= 0.010990087, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.0014096084, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.0018062931, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00828336, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 800, training loss= 0.00034360992, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.0011482139, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.0004452518, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00033666857, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1200, training loss= 7.3411196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.00016483082, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1400, training loss= 0.00013365646, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00012015406, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 9.989801e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.00014627678, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 9.896378e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00013707647, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2000, training loss= 9.413417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 0.0002904884, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2200, training loss= 8.071585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.000113107744, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 6.5728214e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 7.467509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 7.47882e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 0.00014493043, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 4.986713e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2900, training loss= 8.715366e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 8.345896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3100, training loss= 8.374644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 9.8462915e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3300, training loss= 6.850093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 5.7121793e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 5.1049865e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 6.073701e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 4.474434e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 5.698458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 4.537524e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 7.7783116e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4100, training loss= 2.1114298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.4028376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 7.428725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 4.9455317e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 6.0670907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4600, training loss= 3.9265742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 3.3787823e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4800, training loss= 2.222307e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 2.7888911e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.6384652e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 4.268808e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5200, training loss= 1.8342535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 3.640592e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.675147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 4.0683655e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 5.7309517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5700, training loss= 5.3059237e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5800, training loss= 2.1050517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5900, training loss= 2.9001272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 2.1682825e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 2.4490568e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6200, training loss= 5.6777477e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 1.206457e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 1.8631803e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 2.8394177e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 2.064755e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6700, training loss= 1.9105793e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 1.3473336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.6770351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 3.8086808e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 9.083156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7200, training loss= 2.8561692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 2.1495483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 2.2305263e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.7590653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.8775003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7700, training loss= 1.7969975e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.1573217e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.3541719e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.2924986e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.8286872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 2.0161868e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.9373725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 8.702997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.1870059e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8600, training loss= 2.1714874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 8.531334e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 1.3683234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 6.9569533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9000, training loss= 1.028602e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 1.446362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 4.9309697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 1.2126831e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 1.1932704e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.1256293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 9.782787e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 7.105736e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 4.566323e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 7.683178e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10000, training loss= 6.630302e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.8557586e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 6.638747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 7.2090293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 3.390549e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 7.0846722e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10600, training loss= 5.3014383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 5.559007e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 3.6495085e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10900, training loss= 4.144894e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11000, training loss= 3.8692833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 5.5646865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 2.6532234e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11300, training loss= 1.5492373e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.8420288e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 3.52481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.1986982e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11700, training loss= 1.4946331e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 3.4738641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 2.394339e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 4.213718e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 2.7818019e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.381144e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.0114609e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12400, training loss= 1.7353825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 2.762105e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.3178145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 1.6738297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 2.8655863e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12900, training loss= 2.7352635e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 9.059733e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.0988865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13200, training loss= 1.3960894e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 1.2538417e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13400, training loss= 8.654316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13500, training loss= 1.0774263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 1.4088228e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13700, training loss= 5.956388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13800, training loss= 8.853005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 6.6378345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 3.4510845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 5.1637033e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.2424226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 1.027154e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 7.955074e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14500, training loss= 8.4458196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 4.847785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 4.841795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 7.291442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 6.635848e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15000, training loss= 5.25106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 8.404123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.2722545e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15300, training loss= 3.5067077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 3.798765e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15500, training loss= 4.0987763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15600, training loss= 2.0086694e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 3.762983e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15800, training loss= 2.8808694e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15900, training loss= 2.2212514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16000, training loss= 3.1888223e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 2.1119722e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16200, training loss= 3.977578e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.3801812e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.8927866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16500, training loss= 3.0517435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.6152802e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 2.3523779e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16800, training loss= 1.7642911e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16900, training loss= 1.9152844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 3.4709578e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 9.1790945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 8.821453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17300, training loss= 2.3503938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17400, training loss= 1.5795172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 8.5830486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17600, training loss= 9.8744806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 1.0907608e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 1.13049815e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 9.457251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18000, training loss= 1.5755424e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 6.59624e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18200, training loss= 9.735403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18300, training loss= 1.007316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 18400, training loss= 1.140433e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18500, training loss= 8.0664805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 7.4108236e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 6.3975506e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 18800, training loss= 8.920804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 4.410739e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 2.6027344e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 9.6161976e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19200, training loss= 4.0928494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 19300, training loss= 4.649158e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19400, training loss= 3.2981205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19500, training loss= 6.099537e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 4.9670483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19700, training loss= 4.4902137e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 3.655749e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.801416e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20000, training loss= 3.3577265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20100, training loss= 4.549816e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 3.9140343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20300, training loss= 3.4769357e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20400, training loss= 2.2649754e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20500, training loss= 2.3841842e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20600, training loss= 3.2186488e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.622603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20900, training loss= 1.7881387e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 1.529852e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21100, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 3.854431e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21300, training loss= 2.423921e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21400, training loss= 1.76827e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21500, training loss= 1.3709065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21700, training loss= 1.8278751e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.5497204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.8874797e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 1.3311701e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 22100, training loss= 9.139377e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 1.2914334e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 1.17222445e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 8.742013e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 8.940694e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 7.351239e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 1.2318289e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 1.3311701e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 6.159146e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 3.9736423e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 7.9472855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 6.357829e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 8.742013e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 2.5828677e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.9802318e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 4.569689e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 3.3775964e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 2.1855036e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28500, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29700, training loss= 1.9868215e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29800, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 29900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "Valid acc= 98.5 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7636182, training acc= 89.49999809265137%\n",
            "Validation Accuracy valid 88.0 ...\n",
            "\n",
            "step 100, training loss= 0.0014524448, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.002393889, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.13864827, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 400, training loss= 0.0029713945, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.0051878896, training acc= 100.0%\n",
            "Validation Accuracy valid 96.5 ...\n",
            "\n",
            "step 600, training loss= 0.00075327273, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.006071425, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.0008636887, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 900, training loss= 0.00034359877, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.00020992127, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00017444276, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 8.93537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.00022914476, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1400, training loss= 8.4610336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.00015365804, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 4.266093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00011484732, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1800, training loss= 0.00010020897, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 8.292834e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 0.0001145257, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2100, training loss= 0.00012196603, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 8.1921855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 9.842964e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 4.8611888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 8.0116275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 5.582913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 5.1031668e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 7.064959e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2900, training loss= 7.517244e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 4.7207286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 4.1879233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 3.4186698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 4.4159504e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 5.5968543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 5.0703657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.340508e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 4.7673002e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 2.251103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 5.7012665e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 4.6962698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 4.385241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 3.4974462e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 4.0854018e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 3.690291e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 2.8908937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 1.7610624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4700, training loss= 3.1664196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 3.5627796e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 3.0464651e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.517009e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.759404e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 1.9673145e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 8.960804e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.9765514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 2.2240092e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 1.668813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.8317649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.8910123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.2009532e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 3.2012475e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.0280283e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.8704028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.3285839e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 1.5801768e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.552519e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 9.762813e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.0695344e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 8.8103625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.2685976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 8.348381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 1.0402509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 9.683439e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 5.94079e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 6.603427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.2821643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 8.822334e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 6.4213345e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 4.3542923e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 9.515376e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 4.848005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 8.077483e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 5.8962605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 7.2099474e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 4.577006e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 4.092034e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 6.700421e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 3.8339763e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.2160867e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 6.3622447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.250631e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.6400797e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 4.893738e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 3.439866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 3.4113343e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.594419e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.8299346e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.3984117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.6114793e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.7841119e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 3.3087333e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.2500294e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 2.2367042e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 1.8166952e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 1.9553854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 2.6409862e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.9424567e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.595777e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.4432038e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.4477749e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.4052541e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.7197599e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.8244617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.4058462e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.3106868e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.1147757e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.229424e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0220067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.4116162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.997535e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 9.590278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 6.083603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.042517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 8.2849544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 4.5060912e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 5.114039e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 3.9815674e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 5.0842294e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.445209e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 2.5073595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 7.2061374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 3.1391636e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13200, training loss= 4.6511127e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.153072e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 3.576264e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 3.7729563e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.797439e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13700, training loss= 4.525961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.9470808e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 4.7206638e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 2.4855063e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 3.4570587e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 2.1934457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.7596883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 2.8331965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 1.7603206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 1.9192649e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.4557033e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.9669483e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 1.1920912e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.331169e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.8993967e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.7444259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 1.1761971e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15400, training loss= 2.1656297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 9.675813e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.4781924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 1.1344734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 1.6053491e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15900, training loss= 7.6691165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0391059e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 7.232023e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.1404347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 1.00334404e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 5.563096e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 8.0068816e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.2516956e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 4.7286328e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 8.583061e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 4.4703462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 4.0133777e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 3.7352223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 9.179109e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 2.145767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 5.2054688e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 3.6160138e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 5.3246787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 3.6557505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 2.7815496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 3.8345647e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 2.384185e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 2.1457664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 3.2981234e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.741813e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 2.2649763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 2.66234e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 1.9470846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.6291928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.9073482e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 2.5033946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 1.8080073e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.5099841e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 2.6623402e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 1.4702476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 1.9073486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.9073484e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.88748e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.2516974e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.11261995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 9.536743e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 4.9670534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 9.735425e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 9.934106e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 4.3710067e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 6.755193e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 5.7617817e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 3.178914e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 1.3907749e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26400, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27100, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27200, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 0.12636083, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 1.5009055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27700, training loss= 4.5446195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 0.00019335095, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 2.0004713e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28000, training loss= 0.00024587451, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28100, training loss= 5.17878e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.8015188e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28300, training loss= 1.2475813e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.16426875e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.2762443e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 2.4796489e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28700, training loss= 8.874821e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 3.9667257e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 1.3271837e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 3.1669373e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 5.0436165e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 3.8146922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 2.386263e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 8.116291e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.4715047e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 3.1947408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 5.6322995e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 8.512951e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 6.2739383e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.7304913, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 100, training loss= 0.024764434, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.00072215847, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0033973714, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.0005037752, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.0030435477, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.0022072683, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.0008827405, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00044512466, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0021594528, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0021753563, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.000990368, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1200, training loss= 0.0021206276, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00036779614, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1400, training loss= 0.0037439256, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.00082475785, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1600, training loss= 0.00024784182, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.000190548, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 0.000101983955, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00021216992, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2000, training loss= 0.00011386407, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2100, training loss= 0.00011138018, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 8.63583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 5.57357e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 5.417957e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 0.000108176755, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 0.0001890949, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 5.0819992e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 6.838632e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 5.6099372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 5.2011772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 2.472774e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 6.274405e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 4.713733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 9.317016e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 3.7877868e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 2.8687671e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 5.5696095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.441774e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 6.780889e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 4.309848e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.5136407e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.2342344e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 6.198066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 4.228693e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 4.623733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 5.259833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 4.8154747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 2.9219354e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 4.8661506e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 2.720072e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 1.737663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 3.3301876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 1.9597674e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.303492e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 2.149919e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.0326766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5700, training loss= 3.693348e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 3.0893876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5900, training loss= 1.4200576e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 1.0393646e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.36700555e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 2.2173379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6300, training loss= 2.4110748e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 2.927052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 2.1804688e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 3.3416698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6700, training loss= 1.1375284e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 3.0013467e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 1.5185645e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 1.9262208e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 7.24648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 1.9320647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 1.0112638e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.3421217e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.6355956e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 2.1810254e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 9.434999e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.3208644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.3258212e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.6602802e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.3406531e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 8.6087675e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.1284631e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 1.3691073e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.1275537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8600, training loss= 1.0726529e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 5.316216e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 1.3310492e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 7.1013837e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9000, training loss= 7.122497e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 5.4317516e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 5.995298e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 6.4786645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 8.058474e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 4.1793282e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 5.9965755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 7.325073e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 5.3627527e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 8.09692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 3.2421524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 7.312679e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 6.890297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 2.465615e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 3.6471156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 3.6296326e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10600, training loss= 5.547755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 3.7599389e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 3.9908955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.801147e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 4.700158e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 3.3630324e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 5.625648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 5.4111997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.9192797e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 4.2606243e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.0359045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.8398329e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 2.0259854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 3.4805132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 1.8117825e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 2.1677497e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 2.0436332e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 2.1751746e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.8606397e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.8549617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 7.8841043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 1.5198765e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 3.0305584e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.3752001e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13000, training loss= 1.1393081e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 6.4402093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 13200, training loss= 1.4075287e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 1.7976179e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 1.3381026e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 1.8223251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 7.575585e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 1.0067002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 1.0707812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 1.2458647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 14000, training loss= 5.9276107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.170657e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 4.3049062e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 8.118035e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 5.939553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 6.636888e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 5.1080553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 5.84716e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 4.2199778e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 4.5060816e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 4.944158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.769806e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 7.1345886e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 6.8634006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 3.6373513e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 2.7134763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 3.5032457e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.5778866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.583847e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 2.2739103e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.7374686e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 4.950135e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.00433624e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.3543706e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 3.3408233e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 16500, training loss= 2.539148e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 3.71484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 2.3931165e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 3.0442934e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 2.3037137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.3798397e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.6525345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.548226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 8.136021e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17400, training loss= 1.15632865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 2.1725819e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 1.2189115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 7.6591824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.6128566e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 9.909255e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 1.18911075e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 8.0764195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 4.3362352e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 9.626133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.2442453e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.09672335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 8.314835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 7.8976015e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 8.821478e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 4.78327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 5.6624362e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 3.6656832e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 7.733698e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19300, training loss= 4.529949e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19400, training loss= 4.202125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 4.1723204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 2.622603e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19700, training loss= 5.2303033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 3.7699913e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 4.4256414e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 4.52995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 3.4272656e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20200, training loss= 2.8610216e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 2.9057254e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 3.2782513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 3.5762767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 2.473592e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.9371504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 3.576277e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21200, training loss= 1.8477435e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 2.7716155e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 2.4139867e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 2.130865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.16229035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 1.4901157e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 8.493661e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 8.046626e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 9.9837765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.0728834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 1.2814995e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 7.748602e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 9.089707e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.642673e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.642673e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 7.0035444e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.6391276e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26800, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 5.960464e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28100, training loss= 0.14615121, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 0.16133761, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28300, training loss= 0.00042809127, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28400, training loss= 0.02816139, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28500, training loss= 5.3594245e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28600, training loss= 6.424133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28700, training loss= 8.930463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 0.0064306515, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28900, training loss= 0.0013593932, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29000, training loss= 0.00028876038, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29100, training loss= 2.99408e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 3.9986888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29300, training loss= 1.6156795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29400, training loss= 2.3464807e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29500, training loss= 7.012028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 1.301896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 8.8096385e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 2.3575656e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 2.338141e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.5094995, training acc= 87.99999952316284%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.039435677, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 200, training loss= 0.0029222893, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.0010214503, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.00034394336, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.0002726078, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.0003874169, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.00024444636, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 800, training loss= 7.78137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.0002793996, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0002509097, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00022534527, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.0002431607, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00015126858, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1400, training loss= 0.00026668172, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00020671163, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1600, training loss= 0.00011088938, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.0002102695, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.00024402318, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00014018922, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.000118058495, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 0.000169405, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 9.5967356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.00018843854, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.619639e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.00017519623, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.00010826914, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 6.3557294e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 5.8655984e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 0.000116522075, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 7.6885975e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 6.175657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 7.320747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.7774046e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.00010348646, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 7.05501e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 7.633815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 5.044512e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3800, training loss= 5.3543514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 7.600165e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 3.658233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 7.516591e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 3.8953043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 5.268231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 3.604312e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 5.693039e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 4.1753025e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 5.882939e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4800, training loss= 4.570583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4900, training loss= 5.954526e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.8352653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 3.220578e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 4.9572915e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 1.7886814e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 3.347068e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 2.200028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.6758515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.4645338e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.7491753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 1.890632e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 3.0029758e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 9.767324e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.4392694e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.9938734e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 2.1649712e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.1366663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6600, training loss= 1.15115445e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 1.627149e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 9.4102315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.18667695e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 7.315959e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 9.4693305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 9.999106e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 6.817514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 1.0087821e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 1.0298888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.0137086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.0302095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 7.774598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 6.379647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8000, training loss= 8.708265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 4.684891e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 5.9717368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 4.1632193e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8400, training loss= 4.3086106e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 8.625295e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8600, training loss= 9.096246e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 3.021494e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8800, training loss= 3.964501e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.2560058e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9000, training loss= 5.396032e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9100, training loss= 4.86689e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9200, training loss= 2.7238436e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 4.746905e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 2.6210175e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.1935015e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 3.127882e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 1.8012137e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 1.9081392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.85567e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.2672803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10100, training loss= 1.9290576e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 1.8781066e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 1.990749e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 2.3388204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.5172055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 2.0706204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10700, training loss= 1.0570711e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.8903185e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10900, training loss= 1.1977398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.3911481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.1804457e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 7.5905444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 8.422006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 1.308879e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 7.456476e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11600, training loss= 1.1220336e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0493231e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 7.1763264e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.869385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 7.119715e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 8.287952e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 5.593852e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 6.6249885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 4.0590544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 7.5786664e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 3.2961245e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 7.1971675e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.3836154e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12900, training loss= 4.0024162e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 3.42427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 3.3289052e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 4.1872093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.1083673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 4.392842e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 4.8160257e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 3.007029e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 5.453785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.8119763e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 2.086158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 2.9265803e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 2.5570313e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 1.1980515e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.9341665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 2.306693e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.596335e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 1.4036873e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.3977251e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 1.9669494e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 1.14142715e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.5944207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.0728818e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.6629673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 9.775151e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.5914415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 1.4960735e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.3351398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 1.09672364e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 1.0997041e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 7.331364e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.4871326e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.1682496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.1116253e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.84125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 9.685743e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 8.791676e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 5.1557983e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 5.9008553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.6028327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 8.136025e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 4.172323e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 3.159045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 5.0365898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 5.245204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 4.7683695e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 3.5464744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 2.6226035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 3.9935095e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 3.039836e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17900, training loss= 2.026557e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 2.2649758e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 2.7716151e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.0563595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.3709066e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.3245805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18500, training loss= 2.1159643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 2.0563595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 1.6093251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.400709e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.0430811e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.10268585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.0728834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 9.238718e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.49011585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.16229035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 9.536742e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 6.5565104e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 7.7486035e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.025566172, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 95.5 ...\n",
            "\n",
            "step 26400, training loss= 0.0034496982, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26500, training loss= 0.0040100445, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26600, training loss= 0.00511861, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26700, training loss= 4.1705647e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.0001831693, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26900, training loss= 5.6671648e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27000, training loss= 0.0001770996, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 4.699156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27200, training loss= 1.5728401e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 7.700904e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27400, training loss= 7.4260447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 5.681718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 7.393381e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 8.2465034e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 1.3613008e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 3.1198968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 2.7861872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 2.3089022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 3.7146718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 2.1053833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 3.186115e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 2.283511e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 3.856783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 2.3570617e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28800, training loss= 1.779635e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28900, training loss= 2.4203371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29000, training loss= 7.957782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29100, training loss= 1.8808056e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.6190117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.5169241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29400, training loss= 1.2388602e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29500, training loss= 2.2471556e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.6563006e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29700, training loss= 1.2319857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29800, training loss= 2.8784289e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29900, training loss= 7.952098e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7491051, training acc= 91.00000262260437%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 100, training loss= 0.034846384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 200, training loss= 0.0027968925, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.00047345422, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.00033690428, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.0034412623, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 600, training loss= 0.0007994493, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.06041136, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.031878598, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 900, training loss= 0.00096669135, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.0003687142, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1100, training loss= 0.00053446105, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1200, training loss= 0.00048036771, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.00012743808, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.0001659477, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.0001688339, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00016108585, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1700, training loss= 8.44349e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 7.4442396e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 0.00014246671, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2000, training loss= 6.0271857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 8.8449226e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 6.683565e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2300, training loss= 9.433382e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 3.48266e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 9.452199e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 3.536197e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 4.962503e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 7.5803066e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2900, training loss= 5.3583466e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 0.00011115102, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 4.639947e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 8.055888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3300, training loss= 2.217185e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 7.468372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3500, training loss= 5.611888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3600, training loss= 7.5111566e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3700, training loss= 5.248479e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 4.4966724e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3900, training loss= 3.2931985e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4000, training loss= 3.0140853e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4100, training loss= 5.587737e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 4200, training loss= 4.4394117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4300, training loss= 2.7067463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 5.3845055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4500, training loss= 4.7568883e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4600, training loss= 2.760794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4700, training loss= 2.4561949e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4800, training loss= 3.833233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4900, training loss= 2.414298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5000, training loss= 3.2821878e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 2.6419088e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5200, training loss= 3.0928026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5300, training loss= 3.172096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5400, training loss= 2.9084766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 4.960324e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5600, training loss= 1.702319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5700, training loss= 3.1217234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5800, training loss= 2.1078644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5900, training loss= 1.9665416e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 3.102241e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 2.3703633e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6200, training loss= 1.190164e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 3.925997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 2.682143e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 1.8846249e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 1.1859872e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6700, training loss= 2.855706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.5393258e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 2.198239e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 2.3099368e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 2.3651934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 3.332225e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.2504407e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.4693432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.1715385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.0993313e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 2.3868442e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.0447887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.3118067e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 7.5397375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.0527187e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.1633114e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.0775805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8400, training loss= 1.407657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 8.719276e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.2441643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 9.942413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8800, training loss= 9.356401e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.113451e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 6.2375984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0537907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 3.4513328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 3.542377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 4.840788e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 7.922656e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 4.8024226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 3.311136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 6.2441645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 5.7440457e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 6.286357e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 4.602099e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 3.6908616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 5.3517865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 4.891503e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10500, training loss= 3.3034005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10600, training loss= 5.554033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 4.325919e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.3685297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 3.9670913e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 3.1605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 1.5436977e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 3.1449933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 2.311484e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 2.1916028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.5230588e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.415313e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11700, training loss= 2.6025407e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 1.3350995e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 11900, training loss= 2.8675822e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12000, training loss= 1.9370934e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 1.328794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12200, training loss= 1.3141361e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.3128187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 1.2933568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12500, training loss= 2.231692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12600, training loss= 1.8400432e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 9.240939e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 12800, training loss= 7.4671203e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.9659087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 8.5793647e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13100, training loss= 1.4408387e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 5.378687e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 5.118801e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 7.263327e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 1.0149259e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 1.2730089e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13700, training loss= 7.9726226e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 6.0366494e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 6.989159e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14000, training loss= 7.107143e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14100, training loss= 8.423157e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14200, training loss= 5.671921e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14300, training loss= 7.487463e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 4.2795787e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 8.196721e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 4.985288e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 6.4455566e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.2506367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 4.1126978e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 4.2056612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 3.104176e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15200, training loss= 4.6896585e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 5.0877617e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 4.868468e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15500, training loss= 5.917487e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15600, training loss= 4.039961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 15700, training loss= 2.9337158e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.3078768e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 1.5497163e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 2.0933044e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16100, training loss= 3.00406e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.6331612e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 2.1290678e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.7954385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 2.1362237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.7249492e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 2.0170113e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 1.561638e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 7.200231e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 1.635547e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.4829605e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 1.1563275e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 1.0514238e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 1.1396386e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 1.01327714e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 17600, training loss= 1.04665524e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 5.8412436e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 7.7962746e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 1.5044178e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 8.022774e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 8.65458e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18200, training loss= 6.9379645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 5.3286477e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 5.078311e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 8.225427e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 6.747238e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 4.6014744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18800, training loss= 3.838537e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18900, training loss= 5.292885e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 5.531306e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 7.414811e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 2.8610183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 3.0517565e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 4.8875773e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 4.756447e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.8610211e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 4.3392152e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19800, training loss= 1.740455e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 3.0517562e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 2.431868e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.454353e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 2.7179704e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 2.0027157e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 2.0980828e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 3.6001182e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.7404552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 2.5629987e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 2.1457662e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.9311898e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.704692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 9.53674e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.1444089e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.1444088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 1.3709062e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 1.5020367e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 2.0265574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.5497204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 9.77516e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 8.821486e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 7.867811e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.867812e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 6.4373005e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 3.814697e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 7.3909754e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 7.629394e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 4.0531156e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 3.0994411e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 2.7418137e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 4.0531156e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 3.0994414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 1.6689299e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 1.6689299e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26700, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.112007275, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 0.11103656, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 0.0005116432, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 9.75468e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27400, training loss= 0.008496265, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 5.7019173e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27600, training loss= 0.0004373042, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27700, training loss= 1.1850859e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 2.3806272e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27900, training loss= 2.7104883e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28000, training loss= 9.759002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28100, training loss= 2.3935432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28200, training loss= 1.0788e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28300, training loss= 2.4006331e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28400, training loss= 2.4710875e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28500, training loss= 6.238008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28600, training loss= 3.3717086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28700, training loss= 1.6770267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28800, training loss= 1.710619e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28900, training loss= 1.4606363e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29000, training loss= 2.031028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29100, training loss= 8.3561845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29200, training loss= 1.5126936e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29300, training loss= 3.6813908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29400, training loss= 1.4453636e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 2.6563843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 1.6650685e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 1.752893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 1.6865813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29900, training loss= 5.1087663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.14847247, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 94.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.0007601454, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.0062709516, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.00041410883, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.018620707, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.00094815134, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.00047243008, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.00019986519, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 800, training loss= 0.0002234125, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 900, training loss= 0.00031657013, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.00017952269, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00015443658, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00014692658, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.00018098918, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00023744153, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.000103558945, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00012654845, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.0001302577, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1800, training loss= 9.935229e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 9.933386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 9.201987e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2100, training loss= 9.5115174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 0.00012162826, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 8.828254e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 0.00011542862, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 9.615535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 7.242731e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 3.2542845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2800, training loss= 9.252827e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 2.7502243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 7.2430645e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.4835316e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 8.825268e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 5.4219643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 3.3850585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 3.0782274e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 5.4826043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 4.1017585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 5.276399e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 3.4302393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 3.2332002e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 3.6150792e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 4.4243556e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 1.4400564e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 2.9570925e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 3.4416033e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 2.4489924e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 3.7464997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 1.7821938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 3.6904687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.1947513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 1.062126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 1.6229103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 2.0709907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 2.3617691e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 1.1845765e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.5679694e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 1.5038126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 7.5704993e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.5022351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.8019406e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 1.6936581e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.232541e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.18999815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 1.0497903e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.4213764e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.7636456e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 4.6242885e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.18226235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 6.5555055e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 4.8518627e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 7.4627187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 8.263121e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 7.917012e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 5.2882624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 5.1350253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 1.0090554e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 9.185651e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 6.505415e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 6.2839044e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 4.9021405e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 3.8857816e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 3.6776676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 6.341853e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 3.4922955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 5.8767273e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 4.4723574e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 3.2225844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 4.149103e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 1.452396e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 3.3337114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 2.3051564e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 1.9564932e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 1.2847678e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.717753e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 1.6361012e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 1.6295547e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 1.9295053e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 1.1090625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.2548023e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.1157888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 2.5792895e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 1.6151013e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 1.0733162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 1.2195002e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 7.308938e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 1.4850286e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 1.0086438e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10800, training loss= 9.4815323e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 1.3936844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 6.3254976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 7.3089427e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.5289888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 1.0713821e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 9.028518e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 6.645876e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 7.389442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 4.5358885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 5.552135e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 4.231914e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 6.581788e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 4.9665243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 6.696544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 4.8502847e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.1958747e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 4.793684e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 4.1261177e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 5.39121e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 2.6509105e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 6.4640886e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 1.6719059e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.591442e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.792468e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 1.3768653e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 2.3379826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.829859e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.710514e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.8118396e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.8522104e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 1.6525361e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 2.384181e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.0950999e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 1.1667598e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.799919e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 1.5869719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.164205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 1.12354655e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.2963997e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.2278537e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 8.0913225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.00880754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 7.599584e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 8.374445e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 5.230305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 5.677339e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 4.4256417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 6.7949244e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 5.364415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 7.7933024e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 6.213781e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0371191e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 4.78327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 9.7453466e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.1856006e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 3.21865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 3.933906e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 6.73532e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 6.7502235e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.409118e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.919003e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.7997946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 4.664061e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 2.8610218e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 3.7103877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.096195e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 2.1010626e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 2.4139872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 4.306434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 2.0116564e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.8775461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 1.5646217e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 2.279877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 2.0563599e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 1.2665984e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.0877846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18600, training loss= 2.279877e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 2.0563597e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.877546e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.3411043e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 1.02818e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 1.1622903e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 9.834765e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 8.493661e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19700, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19800, training loss= 7.897615e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 8.791685e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20000, training loss= 7.3015682e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20200, training loss= 5.8114527e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20400, training loss= 1.2069938e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 6.258487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20600, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20700, training loss= 5.8114527e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20900, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.9371509e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 21100, training loss= 2.235174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21200, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21300, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 21400, training loss= 4.917383e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 4.0233132e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 2.8312204e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 2.235174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.1292435e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.0430813e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 1.3411043e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 4.4703483e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.1794868, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 91.19999694824219 ...\n",
            "\n",
            "step 24900, training loss= 0.05283235, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.024460968, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 25100, training loss= 0.0011026246, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25200, training loss= 0.0037383218, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 25300, training loss= 0.007821645, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25400, training loss= 2.9168423e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25500, training loss= 0.00014622895, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 25600, training loss= 5.9074697e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 25700, training loss= 4.7847083e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25800, training loss= 7.369522e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25900, training loss= 2.8571852e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26000, training loss= 3.942655e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26100, training loss= 3.220571e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 26200, training loss= 3.3161654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26300, training loss= 2.0020156e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26400, training loss= 8.432376e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26500, training loss= 4.895209e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26600, training loss= 4.6962043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26700, training loss= 3.5029458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26800, training loss= 6.3240573e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26900, training loss= 2.9128441e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27000, training loss= 4.7755293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27100, training loss= 2.4796074e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27200, training loss= 7.1433337e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27300, training loss= 2.4853827e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27400, training loss= 2.1829412e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 2.6021942e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 2.898441e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27700, training loss= 1.9363055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 1.187242e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 1.2992667e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 3.7369962e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 1.6083064e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 1.2791265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 1.2738248e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 1.0155272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 1.7903318e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 8.328605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 7.0235537e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28800, training loss= 2.1747273e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28900, training loss= 6.9265398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29000, training loss= 1.7684783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29100, training loss= 8.7655435e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.4506243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.0134418e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29400, training loss= 5.924403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.476949e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.2289474e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29700, training loss= 7.034543e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29800, training loss= 9.128639e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 29900, training loss= 1.083224e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.3014907836914 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.4625556, training acc= 86.50000095367432%\n",
            "Validation Accuracy valid 84.5999984741211 ...\n",
            "\n",
            "step 100, training loss= 0.009873457, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.009675698, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.06272699, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.4000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.009281827, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 500, training loss= 0.0023525394, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.000796955, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.007612922, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.008417513, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.04200749, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0 ...\n",
            "\n",
            "step 1000, training loss= 0.0010823058, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.011957829, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.005447494, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.00016969378, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.00025642803, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1500, training loss= 0.00018994625, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 0.00011148728, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1700, training loss= 0.0001519523, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 5.1344472e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1900, training loss= 0.000114705, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2000, training loss= 0.00017647487, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 0.00016669072, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 7.0707545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2300, training loss= 0.00014605207, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2400, training loss= 0.00019520438, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 0.00012533748, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2600, training loss= 9.3231065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 0.00013419885, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2800, training loss= 0.00015070809, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 6.698415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 7.4300464e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 7.788869e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 6.204043e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3300, training loss= 6.954175e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 0.000101137164, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3500, training loss= 0.00014247942, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 3.9282517e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 6.19493e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 0.00012098811, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 7.959501e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 2.0376454e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 4.5651745e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 5.053907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 5.738453e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4400, training loss= 6.5646214e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 7.19845e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 4.2279626e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.0300577e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.6554233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 3.9958282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 4.414931e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 8.059281e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 4.4121003e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 4.0030613e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 2.980649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 3.2697437e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 1.987078e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.3039963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 2.044901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5900, training loss= 1.324795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 3.006205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 2.0659782e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 2.8798682e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6300, training loss= 3.736447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 2.926903e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 1.9375326e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 2.0508218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6700, training loss= 3.2549677e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 4.4712488e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 2.3236962e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 2.9457082e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 2.1961814e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 2.5960593e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 2.216319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.39927015e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.7645887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.9442721e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7700, training loss= 2.262071e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.6021906e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.5504424e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 1.5671989e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8100, training loss= 1.2741196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.2926779e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.0557667e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8400, training loss= 1.09657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.4000293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.5243709e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 1.6457901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 5.975668e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 6.3747534e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 6.679973e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 7.3154283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 6.9534776e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 5.8046176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 1.2720513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.6647705e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 9600, training loss= 4.9250134e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 7.0780306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9800, training loss= 8.165239e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9900, training loss= 4.324812e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10000, training loss= 5.124565e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.060113e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10200, training loss= 4.5891775e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 4.454139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10400, training loss= 2.5667296e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 5.3375766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.954761e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 2.921967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 10800, training loss= 3.5418911e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10900, training loss= 1.7839251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 1.8321765e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11100, training loss= 3.414253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 2.3481068e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 2.809641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.2566621e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 2.5879533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 6.2190503e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.6484897e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.7702238e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11900, training loss= 1.532734e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.0999341e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 1.556374e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.5289532e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.3946088e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12400, training loss= 1.0038367e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.5996262e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12600, training loss= 1.4872192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 1.2217483e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.3159212e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.6888064e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 9.1527846e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.5043951e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13200, training loss= 1.5712758e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 6.8937896e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 1.5219156e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 8.4899415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 5.999765e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 1.1037449e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 8.475642e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 8.4673076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 5.1891465e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.828087e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.5517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 6.4861297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 6.718564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 5.9866505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 5.3917927e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 4.3785363e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.6476286e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 4.5418423e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15000, training loss= 5.5074395e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.99484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 2.7215384e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 5.357237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 2.60352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 3.181685e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.888267e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.650015e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.8192883e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 2.7215398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16000, training loss= 1.4734239e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.7739915e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.3446785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 2.1207283e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 2.4998124e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 2.6214005e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.3554077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 1.8143614e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 2.2244394e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 9.5844165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17000, training loss= 2.2160962e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 1.2016282e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.3518307e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.1193731e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 1.6307804e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 9.798988e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 8.690347e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 6.830686e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 1.108645e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 8.904927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 6.878368e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 7.59362e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.731249e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 7.009502e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 4.386899e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 9.310237e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 6.079671e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.8146947e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.9696673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.5537924e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 4.684922e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 5.3644158e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 5.2809664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 4.6014765e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 4.7564487e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 3.0279143e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.3603434e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 2.2530552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 3.2305703e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 2.2172927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 1.9669526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.8596644e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.5020367e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.7523764e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 2.7537338e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 1.9669526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.3947485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.28746e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 9.4175325e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.323223e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.4662741e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 1.2636183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 1.3232229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 7.867812e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 1.04904165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 1.40666945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.466274e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 8.940696e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 1.0013579e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 5.602837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.106231e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.152557e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.026558e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 1.6689301e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 2.2649764e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26300, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 8.3446505e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 26700, training loss= 0.10768938, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.008793372, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 26900, training loss= 0.012823711, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 27000, training loss= 1.2324063e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27100, training loss= 0.012677136, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 1.3485197e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27300, training loss= 3.1230695e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27400, training loss= 1.0392901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 2.1648111e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27600, training loss= 2.415332e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27700, training loss= 8.8522265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27800, training loss= 1.8608886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 1.7186818e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 3.8044805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28100, training loss= 7.1837685e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.2715481e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 1.637915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.3154365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.0271192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 4.4160174e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 1.5864213e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 7.2442067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 2.9943133e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 3.6809759e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 3.192872e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 4.392033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 7.865176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 2.9069377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 2.593819e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.3062578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 2.8372024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 3.7867183e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 7.836629e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.19013658, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 95.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.00093026174, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.0026277967, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.001492311, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0024322432, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.0055890502, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.00030306313, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.003100828, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.0011220517, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0055018878, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.0009811673, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.0002756448, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.00011071658, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.00025124694, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.00016421286, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00011190099, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 0.00010541811, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1700, training loss= 9.068278e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1800, training loss= 0.00010285259, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1900, training loss= 0.00011336279, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2000, training loss= 9.543807e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2100, training loss= 6.598983e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2200, training loss= 0.0001048186, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2300, training loss= 6.791052e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2400, training loss= 8.446564e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2500, training loss= 0.00012669193, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2600, training loss= 5.7286346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 7.6599514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 7.583943e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2900, training loss= 7.213351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3000, training loss= 8.483188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 0.0001235103, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3200, training loss= 5.7044235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3300, training loss= 6.213048e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3400, training loss= 8.943349e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 5.9132086e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.019669e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 5.190742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 7.3327596e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 3.2594657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 3.1536434e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 6.0016704e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 5.3755753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 3.8125934e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 3.6538997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 3.681976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 5.190695e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 4.0097595e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 4.829544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 2.4251223e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 3.4608584e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 2.0206395e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 2.1829377e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 2.141725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.593269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 2.3686447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.7244552e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 2.9091678e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 2.3514032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 1.6609652e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.596803e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 1.2894791e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 1.3850272e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.3748465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 9.598098e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.5380698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 1.3717976e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.531126e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.0051459e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.2853964e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.0743887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 1.392279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7200, training loss= 1.1115343e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 8.731065e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.3423013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 8.573937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 5.6051285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 8.959563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.1156192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 9.093328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 5.699008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 8.97865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 6.377527e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 5.442519e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 5.4422085e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 7.3331244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 3.4193479e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.3501954e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 3.2585556e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 4.601866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 5.73484e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 8.332201e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 2.6594612e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.3757423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 4.614429e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 3.3148297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 2.994404e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.5207094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.716661e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 4.0560403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.5897298e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.4749584e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 4.7529043e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 3.8448393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 2.3756274e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 2.9698388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.7610328e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 3.5251676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.6350413e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.833491e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 2.583909e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.7254063e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.9528363e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.3899358e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.7905795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.4260626e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.2743261e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.1824178e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.1075607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 5.171254e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.1026717e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.1557121e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.0965964e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 7.4981807e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 8.1550235e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.5883385e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 7.0082405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 5.1855665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 8.489946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 7.6567466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 3.2830022e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.02304e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 5.7720746e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 4.4345572e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 5.407294e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 7.266953e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 3.4785123e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 3.2138655e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 3.6835488e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 1.8632356e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 4.3189343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.278083e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.2780837e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 4.6551006e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 3.9064693e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 2.9325346e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 1.4519667e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 2.8550505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.778759e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 1.5878642e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 1.6975366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 2.5105408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.7237619e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 2.3150396e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 2.052776e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 1.5532946e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.3518297e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 1.9955564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 1.4519672e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 1.7869435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 8.475768e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 1.0371191e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.0335435e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 8.976452e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 8.618823e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 1.3113002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.0228137e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 6.866446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 4.5061068e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 4.8637357e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 9.822834e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 9.691693e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 4.2080853e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 5.8174063e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.8293296e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 3.5762763e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 5.7101204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 4.935263e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.5180297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 6.759163e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 4.577633e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 3.7550908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 5.340574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.2530555e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 3.1828865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 2.7656545e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.8252591e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 2.4318684e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 3.1232826e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.076955e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 4.25577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 3.5047517e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.8715854e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 1.9431107e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 1.7523762e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.8954273e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.3589857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 2.3126592e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 9.298322e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.3232229e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.0967251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.823902e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.1086461e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 8.583068e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.3589857e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 1.40666945e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 6.4373014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.1086463e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 1.0013579e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 5.0067896e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 7.0333472e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22100, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 6.7949286e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 4.6491624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 2.861023e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 3.9339065e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.145767e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 3.5762786e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 3.4570693e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.5033948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.3113021e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 1.4305115e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 8.3446505e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 7.1525574e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26600, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 1.0728834e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 3.5762787e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27100, training loss= 0.00049628475, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 1.0487039e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.0063560284, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 27400, training loss= 6.09169e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27500, training loss= 1.2766516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27600, training loss= 4.756465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27700, training loss= 2.0138152e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 1.1392219e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 3.7247166e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28000, training loss= 6.1270885e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 2.4826218e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 1.4615197e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 2.3096518e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 8.548321e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 1.4721978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28600, training loss= 8.3002915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28700, training loss= 1.2625357e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 1.3777887e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28900, training loss= 7.742751e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 3.521224e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 1.1625331e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 1.0342712e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 2.7950875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 4.9842947e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 7.2881144e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29600, training loss= 4.0344307e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29700, training loss= 4.7630215e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29800, training loss= 1.17057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29900, training loss= 8.4733865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.7141365, training acc= 90.49999713897705%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0074453596, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 200, training loss= 0.0009144604, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0011556392, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0052687093, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.0003429781, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 600, training loss= 0.00025804708, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.049575698, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 800, training loss= 0.0019488088, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.051701337, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.030002326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1100, training loss= 0.0077472776, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00019876577, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1300, training loss= 9.024233e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1400, training loss= 8.974371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 8.9546375e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00014210286, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 0.00018890618, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1800, training loss= 9.702795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1900, training loss= 0.00010099527, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00014198791, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2100, training loss= 8.03155e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2200, training loss= 9.9710735e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.00011535117, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2400, training loss= 8.077585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2500, training loss= 9.9031706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2600, training loss= 6.20196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 5.8977676e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 2800, training loss= 0.00010070081, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 6.108279e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3000, training loss= 4.5106906e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.9841175e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 5.907393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 4.209719e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 6.7312016e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 2.7272741e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 7.707601e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3700, training loss= 7.978093e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 2.3837307e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 6.3424e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4000, training loss= 5.4274147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 4.5890218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 4.3613356e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 4300, training loss= 4.9521983e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 3.7869322e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 6.9451555e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 3.733818e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.57006e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.3307286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4900, training loss= 6.0959308e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5000, training loss= 6.312785e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5100, training loss= 2.731221e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5200, training loss= 2.9706269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5300, training loss= 6.433572e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5400, training loss= 3.619432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 4.91137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.5674917e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 1.2786286e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5800, training loss= 3.6947797e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.9430896e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6000, training loss= 2.134277e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6100, training loss= 1.6391627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.103963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 2.3596955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6400, training loss= 3.065319e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6500, training loss= 1.9957584e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 3.1795567e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 2.6485766e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6800, training loss= 2.0281239e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 3.579099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.2436634e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7100, training loss= 2.4378545e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 1.882001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.7350767e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7400, training loss= 1.1065293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.1154377e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 8.33703e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.2613851e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.3134572e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 1.0364819e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 1.6570779e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 9.424848e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 1.5135257e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 1.4990833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 1.2265535e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.0599004e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.0820388e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 7.829222e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 1.0707916e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.348662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 1.2290646e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0312282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 1.2390558e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 9.838934e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 6.499245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 5.473657e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 5.8741857e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 3.9230167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 3.375192e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 5.2452206e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 5.903218e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 4.590292e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 5.589014e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 6.082514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 2.6260811e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.906372e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 2.5236131e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 3.7562318e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 3.0008514e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 4.632992e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 3.2223502e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.8740915e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 3.948306e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 3.1749946e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 2.0445693e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11500, training loss= 3.8900785e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11600, training loss= 3.6731817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11700, training loss= 5.078464e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 2.6606458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 2.9680439e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.0738598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 2.815725e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.5706449e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.1089242e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.8578164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 2.6621826e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 1.0975984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 9.974736e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.3866722e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.7796442e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 5.230249e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 9.995538e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 1.6169129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13300, training loss= 1.1837301e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 8.383242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.2278381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 1.0618398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 8.879924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 4.5805797e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 7.61637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 7.9690517e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 7.887602e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 4.4285986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 14300, training loss= 4.8756146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 5.196464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 3.2712842e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14600, training loss= 3.811684e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 3.6259286e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 3.9279186e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 3.4153206e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15000, training loss= 5.820335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 3.9487844e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.1500858e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 2.0563522e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 2.0374756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 4.0828968e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 3.0149823e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 2.42292e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.0503948e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.316978e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 2.189471e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 2.6851794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 2.1248985e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.6341573e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 1.4384551e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 1.0281785e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 1.7871415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.1056644e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 9.56653e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 1.04307986e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.1553338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.3261976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 1.0838093e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 8.493643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 7.987011e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 1.0758597e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 1.3023586e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 1.23282e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 4.8975078e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 7.957209e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 6.82472e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 7.8181316e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 3.695486e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 9.248642e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 6.7353156e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 7.450572e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 7.2518944e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.6358806e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 5.9604613e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 4.619353e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 4.947182e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.010033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 4.3511363e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 2.9603624e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 3.904102e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 2.831219e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 2.8908236e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 2.4437892e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 4.410741e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 1.8676117e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 3.5862115e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 2.8908243e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 3.0398354e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 2.9206262e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 2.1258987e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20600, training loss= 1.4603133e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 2.4735918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.976887e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.6093251e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.0430812e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.6987318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.996755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 1.1622904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.519918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 9.834764e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 7.45058e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 1.221895e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 9.238717e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 6.854533e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 7.4505797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 6.854534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 6.2584866e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 5.066395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.021732664, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 96.0 ...\n",
            "\n",
            "step 26000, training loss= 4.065458e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 0.010269502, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 1.6831855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.00021952903, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26400, training loss= 3.9125225e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 1.5004598e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26600, training loss= 6.082927e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 1.876794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 4.683961e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 1.6893438e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 5.7578727e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27100, training loss= 3.5213143e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27200, training loss= 3.8073863e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27300, training loss= 9.285785e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 7.257216e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27500, training loss= 1.18348635e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27600, training loss= 2.3288599e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27700, training loss= 3.6785648e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27800, training loss= 5.0734984e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 27900, training loss= 2.892303e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28000, training loss= 5.3037293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28100, training loss= 1.8159358e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28200, training loss= 4.5573865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28300, training loss= 2.9036553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28400, training loss= 7.1590184e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28500, training loss= 1.5684889e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28600, training loss= 1.2261452e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 2.853986e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 6.2794925e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28900, training loss= 7.1493105e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29000, training loss= 6.7924702e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 2.631013e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 6.1907673e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 1.7757769e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 2.6626967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 1.6199251e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 2.8669488e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 2.0942198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 1.1702637e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 2.7612755e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.93843078613281 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.240357, training acc= 85.50000190734863%\n",
            "Validation Accuracy valid 87.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.00072087307, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 200, training loss= 0.010604541, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 300, training loss= 0.0005547491, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.00061997864, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.00030061085, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.0002527497, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 700, training loss= 0.00042292374, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.000133779, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.00021847297, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.0001858882, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1100, training loss= 0.0002035335, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00022087155, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00020502399, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.000119573524, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00016135925, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00023241036, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 0.00013802794, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00020564668, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00017970696, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.00012806633, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2100, training loss= 0.00013740644, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.000104741404, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.00010557528, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.0001370245, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 9.642969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.00010056618, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 0.000101965255, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.00012939224, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.00010101048, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 7.3418385e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 0.00011470896, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 4.7746402e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.00010684254, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 6.681612e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 7.1465045e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 6.3796884e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.478265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 4.8874266e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 5.422483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 6.0372688e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 8.1153245e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 8.310058e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4300, training loss= 2.6912525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4400, training loss= 3.9985393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4500, training loss= 4.7254805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4600, training loss= 2.5460518e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4700, training loss= 4.8057296e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 4.1858537e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 3.2272234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5000, training loss= 4.7587422e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.9853529e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 1.3146597e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 4.8194277e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 4.5807366e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5500, training loss= 2.5900312e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.6406013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.2266395e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 4.1245698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5900, training loss= 4.01718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.9558687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.2121938e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.8255998e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.9564624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6400, training loss= 1.4104778e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6500, training loss= 1.2817856e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6600, training loss= 7.790083e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 1.7202658e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.4445213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 2.091918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7000, training loss= 7.1219297e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7100, training loss= 1.0965941e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.0558951e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.6640362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7400, training loss= 7.5274647e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 9.91309e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7600, training loss= 1.48251465e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.1687644e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.1087876e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 8.414353e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 7.6496835e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.232028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 8.863616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8300, training loss= 9.999422e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 5.7980305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 6.5095164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 6.231801e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.1509533e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.6448375e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.2739158e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.7755434e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 5.1879542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.6441028e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.9093198e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 4.9708538e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 2.632359e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.777344e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9700, training loss= 3.3987578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9800, training loss= 3.0161123e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9900, training loss= 2.442489e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 2.0720563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10100, training loss= 1.9975748e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 2.16029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 2.178145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10400, training loss= 1.8458895e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.4912632e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10600, training loss= 1.4972244e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.0454469e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 1.9919305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.8130879e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 1.2424379e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 8.29984e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.8092544e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11300, training loss= 5.6533764e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 1.5353871e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.0657184e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 9.366682e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.0514067e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11800, training loss= 8.5352207e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11900, training loss= 7.1584344e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.0949204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.008199e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 1.1461756e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 8.240231e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 5.2094146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.6521106e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 7.8498266e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 6.6428674e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12800, training loss= 5.0902077e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12900, training loss= 5.0663544e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 6.5355965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13100, training loss= 2.9981007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13200, training loss= 6.991501e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.0427992e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13400, training loss= 4.7891893e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 2.7358405e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13600, training loss= 4.3451462e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.6494146e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 2.7954454e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 2.616635e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 1.388782e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 2.2023836e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 2.056353e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14300, training loss= 2.7328596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 1.5824993e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14500, training loss= 2.6583552e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 2.226224e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.81333e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 2.3543718e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14900, training loss= 2.3126496e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15000, training loss= 2.0772136e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.7583338e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.096723e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15300, training loss= 1.0550002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15400, training loss= 1.0550002e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 1.3619629e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 1.2516955e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 1.4811727e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 8.2552326e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15900, training loss= 1.0311588e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 1.0460595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16100, training loss= 1.2516952e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16200, training loss= 7.927403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 1.05798065e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 5.1557933e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 8.344645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 5.7816422e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16700, training loss= 5.602831e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 4.261727e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 4.3213337e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 7.301559e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 5.2750064e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 6.25848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 4.9769824e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 2.8014174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 1.2516972e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 5.0365866e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 3.665684e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 3.7550908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 2.801417e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 3.457067e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 1.9073482e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.1888472e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 2.5629989e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 1.6987318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 1.7285343e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 1.639127e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 2.682208e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.8179412e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 2.6822077e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19000, training loss= 2.2947784e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 2.2351733e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.341104e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 8.0466265e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 1.519918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19600, training loss= 8.940694e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19700, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 9.238719e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 1.5795228e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20000, training loss= 8.046626e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 1.3709065e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.2516973e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 1.0132789e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 1.19209265e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.1920928e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20700, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 8.3446485e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 5.6624407e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 2.3841855e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 0.07618469, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 0.079483144, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.7620423e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 0.0008994444, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28700, training loss= 2.3940243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 3.0558513e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28900, training loss= 6.925167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29000, training loss= 8.874664e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29100, training loss= 4.0461928e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 1.7967077e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 3.2079129e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 9.0263875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 8.843295e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 6.6778966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 8.88847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 2.1153843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.066351e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.5 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.5637835, training acc= 88.49999904632568%\n",
            "Validation Accuracy valid 83.4000015258789 ...\n",
            "\n",
            "step 100, training loss= 0.009219123, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.028671242, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.0339968, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.000744403, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.0017800194, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 600, training loss= 0.0066021285, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.0035789192, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.0008883609, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.0006055735, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1000, training loss= 0.00017274884, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00033500823, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.0002683743, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1300, training loss= 0.0001676285, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1400, training loss= 0.00014868894, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1500, training loss= 0.00016313572, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1600, training loss= 0.00017124631, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 1700, training loss= 9.40735e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1800, training loss= 5.2675383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1900, training loss= 0.00015923165, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00010941772, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2100, training loss= 5.985739e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2200, training loss= 0.000118150616, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 2300, training loss= 0.0001165792, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2400, training loss= 0.00013586287, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2500, training loss= 4.287825e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2600, training loss= 3.3790533e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2700, training loss= 7.964137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 2800, training loss= 5.701467e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2900, training loss= 9.243786e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3000, training loss= 7.799166e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3100, training loss= 9.340639e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3200, training loss= 3.677304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 3300, training loss= 8.6567816e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3400, training loss= 6.0278806e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3500, training loss= 7.397346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3600, training loss= 6.843914e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3700, training loss= 8.776783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3800, training loss= 5.9543127e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 3900, training loss= 9.175373e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4000, training loss= 4.402351e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4100, training loss= 2.2397937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4200, training loss= 3.2885026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4300, training loss= 4.080262e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4400, training loss= 4.5756886e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4500, training loss= 5.9554888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4600, training loss= 2.0483687e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4700, training loss= 4.8015147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 4800, training loss= 1.8999515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 4900, training loss= 5.000678e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5000, training loss= 3.1390948e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5100, training loss= 4.341062e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5200, training loss= 3.5542293e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5300, training loss= 3.29073e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 5400, training loss= 3.0748364e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5500, training loss= 2.1142372e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 5600, training loss= 3.6396024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5700, training loss= 1.8799263e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5800, training loss= 5.672108e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 5900, training loss= 2.0149058e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6000, training loss= 3.615231e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 6100, training loss= 1.8298879e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6200, training loss= 5.1910123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6300, training loss= 3.066327e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6400, training loss= 1.1439587e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6500, training loss= 1.9743922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6600, training loss= 2.909969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 6700, training loss= 9.895275e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 6800, training loss= 1.8217193e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6900, training loss= 1.8964653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7000, training loss= 2.850747e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7100, training loss= 1.2582383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 7200, training loss= 1.5819525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7300, training loss= 1.94874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.5780653e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7500, training loss= 1.0326659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7600, training loss= 1.5469042e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 6.6382518e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7800, training loss= 1.649186e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7900, training loss= 1.1612133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8000, training loss= 1.3358386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.200997e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 9.97935e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8300, training loss= 1.5963342e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 8400, training loss= 1.4736417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8500, training loss= 1.2384781e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.0966139e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8700, training loss= 1.2153874e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8800, training loss= 6.3762327e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8900, training loss= 1.3212799e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 8.370498e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9100, training loss= 5.599305e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9200, training loss= 7.3170618e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9300, training loss= 7.3944047e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9400, training loss= 5.7985617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 1.0688096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9600, training loss= 7.312641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9700, training loss= 4.737663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.357037e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 4.169524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 6.464946e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10100, training loss= 2.616641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 7.613475e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10300, training loss= 4.946591e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10400, training loss= 6.5175204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 4.156245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.4063607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10700, training loss= 2.643734e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 4.840908e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.0164205e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 2.8086952e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.1595501e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11200, training loss= 3.9890697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11300, training loss= 2.7695444e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11400, training loss= 2.1670805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 2.4616354e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 2.8973368e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 2.654517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.6394304e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 1.4092485e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 2.1499834e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12100, training loss= 1.6281841e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.0322422e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12300, training loss= 1.531545e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 12400, training loss= 2.2337817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12500, training loss= 1.1781003e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.0956027e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12700, training loss= 1.8034227e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 1.0394018e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 5.2493897e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13000, training loss= 7.139658e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.3696742e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 8.603279e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 1.1339162e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 1.2074739e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13500, training loss= 7.863428e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13600, training loss= 6.8152826e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 8.515626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 7.3005623e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 5.674273e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 8.7864754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 6.411636e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 5.2187596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 6.15794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 4.2395635e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 4.7564095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 4.6976615e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 5.61982e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 3.1113345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 4.4260295e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 2.5621335e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15100, training loss= 4.2506082e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15200, training loss= 3.933879e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15300, training loss= 3.5430352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 3.1496637e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 3.7755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15600, training loss= 2.9478602e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 2.725621e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 2.6285505e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.405113e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 2.2377196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.8060149e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 2.0120724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16300, training loss= 1.6859549e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 2.0725307e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16500, training loss= 1.901383e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.9184115e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.6476366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 1.1980512e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16900, training loss= 1.7140543e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17000, training loss= 9.340883e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17100, training loss= 1.9873822e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 1.7029862e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17300, training loss= 1.1546246e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 1.1111979e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17500, training loss= 8.148793e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 8.685232e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 7.1355174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.276517e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.1818729e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18000, training loss= 1.16228854e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18100, training loss= 6.811953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 3.3463742e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 6.616106e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18400, training loss= 5.7475837e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18500, training loss= 5.6964954e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18600, training loss= 4.2148958e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 4.734308e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 2.2479462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 3.474097e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 3.371918e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.0994396e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 2.8354767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 2.0691315e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 3.8572693e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19500, training loss= 3.065381e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.7370493e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 3.0142907e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 2.6311184e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.4778494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20000, training loss= 3.627366e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20100, training loss= 2.3671552e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 1.8647734e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20300, training loss= 1.5326908e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 2.8354767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 1.9669525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 2.247946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.9924979e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 2.247946e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.0435873e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.3538767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 1.1495181e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 1.592295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.8818033e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 9.9624895e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 7.4080053e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 9.9624895e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 9.451592e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 6.4713612e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 1.0728835e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 6.3862116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 7.663454e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 6.3862116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 3.3208303e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 5.875315e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 6.6416597e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 8.174351e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 5.619866e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 3.5762788e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 3.3208303e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.8099332e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 5.875315e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 4.172325e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 4.087176e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.150531e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 7.6634543e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.5544848e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 1.2772424e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27000, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 5.10897e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27700, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 7.663454e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28000, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 1.5326908e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28300, training loss= 2.554485e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 0.11982353, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28600, training loss= 5.7371297e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28700, training loss= 0.002606958, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28800, training loss= 0.0016902818, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 0.00011953538, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.005635671, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29100, training loss= 0.0002883323, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 0.0006777974, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 0.00031814972, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 3.1952416e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 1.09939165e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 1.8625235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 2.4129022e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 2.3158775e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29900, training loss= 1.640398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.3014907836914 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.3519716, training acc= 87.00000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.0009528943, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.003006239, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.014029461, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 400, training loss= 0.0015689554, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 500, training loss= 0.0003099327, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00030536676, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.03523389, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00039316947, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 900, training loss= 0.00039418964, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1000, training loss= 0.0010337114, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1100, training loss= 0.00062609004, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 1200, training loss= 0.00021209747, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1300, training loss= 0.0001306783, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1400, training loss= 4.746507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1500, training loss= 9.367379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 9.05381e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1700, training loss= 4.580253e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1800, training loss= 4.2583804e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1900, training loss= 5.3734188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2000, training loss= 7.2573726e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 5.3641164e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2200, training loss= 3.843553e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 4.4612098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2400, training loss= 6.1662984e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2500, training loss= 0.000104323626, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 4.348726e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2700, training loss= 4.2048243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 3.371978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 7.642993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 2.5509988e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 6.684009e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3200, training loss= 2.5878713e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3300, training loss= 3.7779122e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 2.2883649e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 4.758754e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 3.0657113e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3700, training loss= 2.8887041e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3800, training loss= 3.2864176e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 3.732585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 5.088799e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 3.419403e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 2.3272509e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 2.7392243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 3.9352435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 2.3834718e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 2.0721232e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 1.4677913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 3.049585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 1.9331095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.1888e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 1.3766056e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 2.1681566e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 1.500228e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.5583608e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 1.6841575e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 1.7202525e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 1.7157108e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.0916995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 1.6099933e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.2681335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 9.948798e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 7.475171e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.5907854e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 9.327078e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.026643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 6.4742485e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 6.6350053e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 3.7976392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 6.5302593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 6.3062303e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 7.660167e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 6.4459723e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 9.755237e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 5.9006593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.1660866e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 7.315005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 7.629828e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 6.098802e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 4.431427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 4.212194e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 6.3657767e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 5.108661e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 4.8544553e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 2.3476496e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 3.904682e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 5.2775117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 2.5992967e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 5.197542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.4326245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 3.1559794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 2.4537435e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.9838131e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 2.6144287e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.1462056e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 1.8924104e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9600, training loss= 2.1578867e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9700, training loss= 1.3227204e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 1.8188492e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.0837114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 2.441226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 1.2795639e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 9.5056566e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 1.4546888e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 1.684517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 8.5973164e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.1005285e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 1.1821861e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.025697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.3952018e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 5.631402e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 1.1376029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 9.2362524e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 8.362464e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.1725314e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.162041e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 6.846139e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 5.8638676e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11800, training loss= 5.9258434e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11900, training loss= 6.313289e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12000, training loss= 7.460071e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 3.0612864e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 5.589695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 3.8528333e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 6.052225e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 6.7758185e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 6.645871e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 4.2009188e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12800, training loss= 3.8301724e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.587864e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 3.4558644e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13100, training loss= 2.4926575e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 4.5513897e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13300, training loss= 3.0469775e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 2.2900056e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 1.9466829e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.8812818e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.3269595e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 2.0170174e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 2.499814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 2.6416683e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 2.950421e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 1.5592553e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.0108937e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 1.776216e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 1.5032272e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14600, training loss= 1.6486621e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14700, training loss= 1.6164756e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 2.3364976e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 1.1205658e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15000, training loss= 8.583062e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 1.3136845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.10268495e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 15300, training loss= 9.810914e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15400, training loss= 1.1301029e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 7.092948e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 8.726113e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 9.21487e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 5.781647e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 5.388256e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 7.748599e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 7.450577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 5.14984e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 8.058544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16400, training loss= 4.1961655e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 4.3153747e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 3.671645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 5.6743563e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 6.580348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 2.145767e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 3.6597246e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 4.8756586e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 2.3365017e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 3.0040734e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 3.5166725e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 3.1232826e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 3.099441e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 2.8252595e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 2.6702873e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 1.4781951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.3841855e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 2.0980833e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 2.4199483e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 2.0623204e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18800, training loss= 1.6212462e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.7762183e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 1.144409e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 1.144409e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.5258788e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19400, training loss= 1.6689297e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19500, training loss= 1.04904165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 1.4781951e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 1.0251998e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 8.225441e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19900, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 7.748603e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 9.655952e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 5.2452083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 5.7220455e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 6.6757195e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 2.6226041e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 2.503395e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 4.8875806e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 6.1988827e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 5.364418e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 4.4107433e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 4.291534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 3.2186507e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.9073487e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 1.4305114e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 3.3378598e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 1.5497207e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 9.536744e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 1.5497207e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 4.768372e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 1.0728836e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 2.8610228e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.1729553, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 95.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.0031946634, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 25100, training loss= 0.00025052714, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 25200, training loss= 0.0047556064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 25300, training loss= 0.00039012992, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.0019254637, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 25500, training loss= 0.0009243777, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 25600, training loss= 0.0037950636, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 25700, training loss= 0.0002131526, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 25800, training loss= 0.00033333493, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 25900, training loss= 9.50662e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26000, training loss= 5.5164932e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 26100, training loss= 6.2116036e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26200, training loss= 0.00012879116, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.00013183773, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 26400, training loss= 6.066161e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26500, training loss= 5.828503e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26600, training loss= 0.00014434585, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26700, training loss= 6.5723725e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.00013109639, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 26900, training loss= 5.679692e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 27000, training loss= 1.4003347e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 27100, training loss= 5.0567993e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 27200, training loss= 5.742894e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 27300, training loss= 3.3297933e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27400, training loss= 4.2237552e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27500, training loss= 4.8522703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27600, training loss= 2.9742963e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27700, training loss= 2.129703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27800, training loss= 2.1666032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 27900, training loss= 2.1551958e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28000, training loss= 2.329084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28100, training loss= 2.5134379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28200, training loss= 4.9698e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28300, training loss= 2.1453234e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28400, training loss= 1.6060341e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28500, training loss= 3.4785953e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28600, training loss= 4.0305527e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28700, training loss= 1.1208098e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28800, training loss= 1.6175867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 28900, training loss= 2.3721153e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29000, training loss= 1.4099831e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29100, training loss= 2.7127657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29200, training loss= 1.2386997e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29300, training loss= 1.923202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29400, training loss= 9.747781e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29500, training loss= 8.271617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29600, training loss= 1.8319597e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29700, training loss= 1.1474658e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29800, training loss= 7.541031e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 29900, training loss= 1.7230459e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.08917236328125 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.4353279, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.0023052054, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 200, training loss= 0.00817067, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0012017189, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 400, training loss= 0.0019304784, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 500, training loss= 0.0011654797, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 600, training loss= 0.0024550452, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.0019152034, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00040729338, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 900, training loss= 0.0037700261, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.00527143, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 1100, training loss= 0.00017237726, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 1200, training loss= 0.0004813281, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 1300, training loss= 0.0001397225, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.00024952108, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1500, training loss= 8.417386e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1600, training loss= 0.0001752477, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1700, training loss= 7.580368e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1800, training loss= 7.096267e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1900, training loss= 7.655546e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2000, training loss= 0.00012819025, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2100, training loss= 0.00011084802, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2200, training loss= 6.95028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 2300, training loss= 0.00013003117, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2400, training loss= 7.066823e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2500, training loss= 6.038435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2600, training loss= 4.9352657e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2700, training loss= 5.35837e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 9.045679e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 6.712659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 4.825196e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 3.356384e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 3.754795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.1368664e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 5.7147125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 6.498417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 2.2050423e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.576332e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 6.4594205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 4.001712e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 2.3424298e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 5.2356507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 5.2146053e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 4.7952497e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 2.306709e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 3.150861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 3.2143907e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 2.27654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 4.046918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 4.7465153e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 3.2441218e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 2.1702464e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 2.487742e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.9062137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 1.9037901e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 3.4690544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 4.4863158e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 3.3629243e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 1.814534e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 2.1962673e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 2.4901772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.1438396e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 2.518539e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 2.2726628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 2.1718959e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 9.16725e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 1.37141205e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 2.3904355e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.6641432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 2.3209275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 1.00211855e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 2.0758102e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.8091861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.6848642e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 7.1548e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 8.754681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.1048828e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 1.08617705e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 1.0820899e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 1.431282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 6.1394758e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 1.1510084e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 1.0234857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 5.8081164e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 1.210195e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 4.71322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 7.745655e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 8.386487e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 1.3572065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 7.234663e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 4.9971045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 4.239033e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 5.749447e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 3.9238816e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 5.477398e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 7.675773e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 6.401778e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.8150787e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 2.910181e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.831391e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 5.557418e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 3.475434e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 2.9240425e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 2.0966415e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 3.087136e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10500, training loss= 2.2135805e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 2.9673515e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 3.2271935e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 2.4433057e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 1.468637e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 2.3491589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 3.3168315e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 1.9718705e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 2.0837392e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.718139e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 2.4965427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 1.7829245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 1.1739949e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.3384041e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 1.0300517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.5389562e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 1.0319427e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 8.730026e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 9.278356e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 1.2689695e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 1.2989624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 7.994861e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 1.5140245e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 5.133902e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 1.0366132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 6.3339417e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 1.1051603e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 6.069677e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 6.9170665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 5.586867e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 3.9775966e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 6.5167114e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 5.963399e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 7.6730606e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 7.405814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 4.330259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14100, training loss= 4.85476e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 2.5947725e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 3.2663172e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 3.8742775e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 3.190822e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 2.8888243e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.634515e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 2.8530624e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14900, training loss= 6.2852564e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 3.2017493e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 1.8715814e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 2.912668e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 2.6186208e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 2.499417e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15500, training loss= 1.6887945e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 1.6967428e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15700, training loss= 1.8517133e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15800, training loss= 1.3609709e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 1.3788525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16000, training loss= 1.8993961e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.581865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16200, training loss= 1.622237e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.13646045e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16400, training loss= 7.480377e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16500, training loss= 1.056988e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 1.9192672e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16700, training loss= 1.2000373e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16800, training loss= 9.53673e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 7.3909696e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 7.867805e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 6.0995376e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17200, training loss= 7.192287e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 5.4041514e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 1.1603026e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 7.867807e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17600, training loss= 9.427454e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17700, training loss= 1.1155994e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17800, training loss= 7.5101795e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 5.6425677e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 8.622797e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 3.496804e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 4.688897e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 1.708666e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 4.4504784e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 4.837909e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 3.9736413e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 3.4570675e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 5.0663935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 2.622604e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19000, training loss= 3.2981227e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 3.0597047e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19200, training loss= 1.8278755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19300, training loss= 1.986821e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 4.1822574e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 3.536541e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19600, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19700, training loss= 3.0597047e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 1.9868212e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 1.9470846e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 1.9470848e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20200, training loss= 1.4702476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 1.5099843e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20500, training loss= 1.4305112e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 1.0331471e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20700, training loss= 2.1855035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 1.2020268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 1.2318291e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.0331471e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 9.139377e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21600, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 21900, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 4.9670534e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 6.357829e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 2.8808909e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23400, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 4.9670534e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 2.4835267e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 8.9406965e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26700, training loss= 0.13311927, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 96.20000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.046874475, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26900, training loss= 0.05061221, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.0041597537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 27100, training loss= 0.014204321, training acc= 100.0%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 27200, training loss= 0.001146232, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.021358844, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 0.0018947971, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27500, training loss= 0.0047540064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27600, training loss= 0.0003114235, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 27700, training loss= 3.8776663e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27800, training loss= 6.4117994e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 27900, training loss= 5.7206264e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28000, training loss= 1.6581589e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28100, training loss= 2.1862379e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28200, training loss= 1.3297419e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28300, training loss= 6.852968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28400, training loss= 1.608867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 2.1707627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 4.0452374e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28700, training loss= 8.984698e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28800, training loss= 3.1582522e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 1.5353715e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29000, training loss= 6.449117e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 2.8671493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 5.4049688e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29300, training loss= 1.6709346e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29400, training loss= 1.3321171e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 5.6156073e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 9.45316e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 3.602549e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 7.384754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29900, training loss= 1.2332417e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.0955105, training acc= 85.50000190734863%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0028113748, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.020106887, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 300, training loss= 0.0075765625, training acc= 100.0%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.0030207026, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 500, training loss= 0.02076395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 600, training loss= 0.0071594287, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 700, training loss= 0.00045671416, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 800, training loss= 0.00037344565, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.0012458521, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 1000, training loss= 0.00021473918, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00014760095, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1200, training loss= 0.00013677847, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1300, training loss= 0.00013461121, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1400, training loss= 0.00021795194, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.0001313438, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1600, training loss= 0.00011562832, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1700, training loss= 0.00014888095, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00013140295, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 0.00010066957, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 0.000112738475, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2100, training loss= 7.613995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 5.3595628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 7.152121e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.671476e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2500, training loss= 0.00010096761, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 2600, training loss= 3.564369e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 5.1420422e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 6.614269e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 7.349897e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 5.164496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 3.2876585e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 6.37733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 6.556921e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 5.9869544e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 6.2773994e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 5.1103998e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3700, training loss= 5.787611e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 4.1437328e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 2.4311628e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 1.4565001e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4100, training loss= 4.5023902e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4200, training loss= 1.8875788e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 4.076463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4400, training loss= 4.7788562e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4500, training loss= 3.184429e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 3.972469e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 1.776609e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 2.9440813e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4900, training loss= 2.2038916e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5000, training loss= 1.7966004e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5100, training loss= 2.8320275e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5200, training loss= 1.2405575e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.2988037e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 3.3130415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 5500, training loss= 1.32359055e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.247483e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 9.296824e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 2.4153762e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 2.7385415e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 1.9255198e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.8501427e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6200, training loss= 2.1512398e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 1.6649432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6400, training loss= 1.2661908e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 6500, training loss= 1.1631276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 1.2810624e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 9.034132e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.0652611e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 9.76632e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 1.1188107e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 8.573692e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 7.988838e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 1.1142546e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 1.05885265e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 1.0540736e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 5.203169e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 7.0639708e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7800, training loss= 7.1809513e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7900, training loss= 8.578989e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8000, training loss= 7.4236045e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.1001803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8200, training loss= 7.1308214e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 5.7187563e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 3.943845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 5.446505e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 7.254146e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8700, training loss= 2.8082854e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 5.5589026e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8900, training loss= 2.1234277e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 5.221008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 4.047283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 5.692058e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9300, training loss= 2.9169641e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 9400, training loss= 3.8244416e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 2.2935446e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 3.1042814e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.504906e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 3.1706138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 3.9283163e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.862589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 3.6190272e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 3.1757636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 1.8427322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 9.73531e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10500, training loss= 2.3000148e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 1.8012147e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 1.5653662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10800, training loss= 1.2071681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.250008e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11000, training loss= 1.4086252e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 1.1070438e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 7.923374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 1.9851818e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11400, training loss= 8.7855835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 1.5202958e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 6.004134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 7.613352e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 4.3312525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 6.9220255e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 1.0176362e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 5.42e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 7.64523e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 7.833968e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12400, training loss= 2.9762452e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 6.8067965e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 6.9895714e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 3.9497866e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 6.608102e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 12900, training loss= 6.8504954e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 7.2200305e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 4.1345547e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.960347e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13300, training loss= 4.4723112e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13400, training loss= 2.8510783e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 3.1669754e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 4.6769503e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 3.496794e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 1.8318434e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 3.3060525e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 1.6530316e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 2.7219292e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 1.5536901e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 2.0980772e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 2.1537078e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14500, training loss= 2.3643126e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 2.1497372e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 1.4861402e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 1.345076e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 1.0609617e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 1.6947558e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15100, training loss= 1.8358199e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.1603023e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 1.18414334e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15400, training loss= 1.7444272e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15500, training loss= 9.695676e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 7.311496e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15700, training loss= 8.6227956e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15800, training loss= 1.4563365e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15900, training loss= 1.0728823e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16000, training loss= 1.0609615e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16100, training loss= 6.119405e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.0689081e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16300, training loss= 8.9009504e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16400, training loss= 8.066485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16500, training loss= 6.715452e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16600, training loss= 9.83476e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 6.7154524e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16800, training loss= 6.735318e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 5.205467e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 5.5829645e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 6.635977e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 5.5034924e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 4.2716643e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 5.1657317e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17500, training loss= 2.9206268e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 3.5365403e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 6.715453e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 4.8279738e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17900, training loss= 4.5895558e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 5.7021744e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 4.450478e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 1.6689295e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18300, training loss= 3.337859e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18400, training loss= 2.8411542e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18500, training loss= 1.4305108e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18600, training loss= 2.3047125e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18700, training loss= 2.2053715e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 1.7086663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 1.5894567e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 2.8212858e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19100, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 1.589457e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 2.1060302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.6689299e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 9.139378e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 1.2318292e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19800, training loss= 1.6291935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19900, training loss= 1.1920927e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 1.390775e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20100, training loss= 9.934106e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.6291935e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20300, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 1.2318292e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20600, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 8.344649e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20900, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 8.742014e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 5.1657354e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 6.357828e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21300, training loss= 5.9604637e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 4.371007e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21700, training loss= 5.5630998e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21900, training loss= 3.9736427e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22000, training loss= 3.1789145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 5.165736e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22200, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22300, training loss= 2.582868e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 2.980232e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 2.7815499e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23300, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23500, training loss= 1.7881393e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 9.934107e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.9868214e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26500, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 7.947286e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 3.973643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 1.5894572e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27500, training loss= 3.283803e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.0999984741211 ...\n",
            "\n",
            "step 27600, training loss= 8.750192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27700, training loss= 0.00017802311, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27800, training loss= 2.1196429e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 1.8985592e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 7.8763205e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28100, training loss= 3.546847e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 1.6731125e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 7.883992e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 1.3357021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 1.3983502e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 1.2783901e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 3.0526621e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 3.755123e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28900, training loss= 8.7105955e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 7.6139836e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 5.894734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29200, training loss= 2.29254e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 9.097336e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29400, training loss= 1.9656381e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 4.0238247e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 5.581168e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 1.5255363e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 7.185875e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.3462383e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 97.87686157226562 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.043932762, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 100, training loss= 0.00346537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 200, training loss= 0.0011190585, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 300, training loss= 0.0012442004, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 400, training loss= 0.021783786, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 500, training loss= 0.022612568, training acc= 100.0%\n",
            "Validation Accuracy valid 96.10000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.008526753, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 700, training loss= 0.0036731793, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 800, training loss= 0.0003066097, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 900, training loss= 0.00044239248, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1000, training loss= 0.027541004, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.0022008778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1200, training loss= 0.00021435294, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 1300, training loss= 0.05735776, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 1400, training loss= 0.0005141321, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1500, training loss= 0.0004150997, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.00011833411, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1700, training loss= 4.3463686e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.00013469311, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.000113486225, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2000, training loss= 6.763822e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.00010155505, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2200, training loss= 0.00011534586, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2300, training loss= 7.263035e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2400, training loss= 6.118358e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.00011097876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2600, training loss= 4.573861e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2700, training loss= 8.1907354e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2800, training loss= 4.1220737e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2900, training loss= 8.37911e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3000, training loss= 4.5873494e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3100, training loss= 6.979296e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3200, training loss= 5.355815e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3300, training loss= 4.9706516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 2.9243054e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3500, training loss= 3.6681795e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3600, training loss= 5.558105e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3700, training loss= 9.076852e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3800, training loss= 3.5366185e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 4.0052702e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4000, training loss= 8.139999e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4100, training loss= 3.2944783e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 4.6386212e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4300, training loss= 6.4070846e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 2.7786818e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 5.3323733e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4600, training loss= 2.0305944e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4700, training loss= 3.0987096e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4800, training loss= 4.204507e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 4.7204703e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.7862954e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 3.3337867e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 3.93738e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 4.0123836e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.8250397e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5500, training loss= 3.340844e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 2.3037133e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.379435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 2.8580007e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 4.6972276e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.1531753e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 2.5730778e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.2070937e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.26575305e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 1.646893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.3563857e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.4728784e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.9740706e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.0944378e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.7237191e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.6347589e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 1.3372672e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 1.1593232e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 6.873226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 8.970844e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.86823e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 1.35795835e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.2734335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 7.63589e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 1.1472493e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 1.64973e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 1.3011335e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8200, training loss= 1.2727216e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 8.41922e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8400, training loss= 6.9051134e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 5.3500094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 8.619766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 9.1507845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 9.704187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 8.358283e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 7.530288e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 7.376592e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 7.1223903e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 4.9204627e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 7.2851317e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9500, training loss= 5.7224943e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 6.3660896e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 4.853605e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.0799845e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9900, training loss= 3.673084e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 3.6151978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 5.018778e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10200, training loss= 4.3387704e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10300, training loss= 5.035393e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 3.0998478e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 4.3450655e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10600, training loss= 5.868524e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10700, training loss= 2.5312145e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 3.5855664e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 2.039097e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 3.6719402e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11100, training loss= 1.6627401e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 2.246681e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11300, training loss= 2.751994e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 4.0859622e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11500, training loss= 2.403876e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11600, training loss= 2.1279636e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 11700, training loss= 2.2112338e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 1.9876795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 1.718517e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12000, training loss= 2.0409645e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 1.9794986e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12200, training loss= 2.0122852e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12300, training loss= 1.121226e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 8.3376744e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12500, training loss= 1.1521322e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12600, training loss= 1.9483273e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12700, training loss= 1.361175e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12800, training loss= 1.4165066e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 1.2780766e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13000, training loss= 1.3518024e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 1.2564403e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 9.152626e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13300, training loss= 6.0864096e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13400, training loss= 4.3545228e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13500, training loss= 9.839789e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13600, training loss= 9.414007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 13700, training loss= 1.3303458e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13800, training loss= 6.7667764e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 13900, training loss= 5.490398e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14000, training loss= 7.271686e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14100, training loss= 4.870499e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14200, training loss= 4.795587e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14300, training loss= 7.9358546e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14400, training loss= 4.965891e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14500, training loss= 8.1325726e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14600, training loss= 4.7334325e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14700, training loss= 2.7792632e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 14800, training loss= 5.359276e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 14900, training loss= 3.4170236e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15000, training loss= 2.9121003e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 3.382125e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15200, training loss= 1.8153827e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15300, training loss= 3.7056924e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15400, training loss= 2.8235408e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15500, training loss= 2.861861e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15600, training loss= 1.743858e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15700, training loss= 3.4749345e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15800, training loss= 2.6021596e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 15900, training loss= 2.9597865e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16000, training loss= 1.66552e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 1.3998549e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16200, training loss= 1.8221955e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16300, training loss= 1.5667482e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16400, training loss= 1.963542e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16500, training loss= 1.7540755e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16600, training loss= 3.3625395e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 1.1035363e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 9.2642516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 1.449242e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17000, training loss= 7.901864e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17100, training loss= 9.2131664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17200, training loss= 1.3436569e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.2568047e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17400, training loss= 1.1886851e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17500, training loss= 6.505416e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 8.1743444e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 8.4127585e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17800, training loss= 1.03967366e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17900, training loss= 7.629383e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18000, training loss= 8.21692e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 5.1600544e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 8.8385086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18300, training loss= 4.8364875e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18400, training loss= 6.7438336e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18500, training loss= 7.322849e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18600, training loss= 6.556505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18700, training loss= 6.003037e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 2.997261e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18900, training loss= 3.3889485e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19000, training loss= 3.5081577e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19100, training loss= 3.8487553e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19200, training loss= 3.0483513e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 2.8269621e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19400, training loss= 2.758841e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 2.3501252e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 2.929141e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19700, training loss= 2.4182446e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19800, training loss= 2.4948793e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 19900, training loss= 3.193105e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 2.7588428e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 3.065381e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20200, training loss= 1.7029896e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20300, training loss= 2.0095277e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20400, training loss= 2.452305e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 1.6518996e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20600, training loss= 1.958438e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 1.7370494e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 2.1117069e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 20900, training loss= 1.805169e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21000, training loss= 1.5326904e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21100, training loss= 1.4645709e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21200, training loss= 1.3623916e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21300, training loss= 1.4986309e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 1.1239731e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 1.328332e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21600, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 9.621892e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 1.2261526e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 7.493155e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 8.429799e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 6.8119594e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 7.1525568e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 8.8555465e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 22400, training loss= 4.598072e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 6.130763e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 8.514948e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 22900, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23000, training loss= 5.449567e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23300, training loss= 6.2159122e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23400, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23500, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23600, training loss= 4.0871755e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23700, training loss= 4.5980726e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 23800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24000, training loss= 4.4277737e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24100, training loss= 1.4475414e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24500, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24600, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 24900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25000, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25200, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25300, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25800, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 25900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26200, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26400, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 7.6634543e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27100, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27300, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27400, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 2.2138869e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27700, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 27900, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 0.08700258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 97.19999694824219 ...\n",
            "\n",
            "step 28200, training loss= 0.0010462438, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 0.007788537, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28400, training loss= 0.0002787191, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28500, training loss= 0.03819514, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28600, training loss= 0.0005042283, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 0.009254003, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 0.00053602253, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 4.780922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.00015877286, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 6.313633e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 1.1946026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 1.9100013e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 3.2852473e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 2.1920068e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 2.3221739e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 3.518542e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 1.7654147e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 2.6732978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.72611999511719 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9243863, training acc= 88.99999856948853%\n",
            "Validation Accuracy valid 88.30000305175781 ...\n",
            "\n",
            "step 100, training loss= 0.0024209036, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 200, training loss= 0.0068702064, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 300, training loss= 0.00035379876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 400, training loss= 0.00045177506, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 500, training loss= 0.00038027472, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 600, training loss= 0.00036243335, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 700, training loss= 0.00017564422, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 800, training loss= 0.00029733498, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 900, training loss= 0.00027954616, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1000, training loss= 0.000161541, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1100, training loss= 0.00017748478, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1200, training loss= 0.00022369123, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.000344609, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 1400, training loss= 0.00015815801, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1500, training loss= 0.00012104943, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 1600, training loss= 0.0002594582, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.00018366707, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1800, training loss= 0.00013618838, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 1900, training loss= 7.929951e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.00015742778, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.00018521569, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.00021373876, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2300, training loss= 9.9257304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 8.3261504e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 2500, training loss= 0.000116200856, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 9.615918e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 9.446045e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.00012584943, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.00011829853, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.00011489536, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3100, training loss= 8.699955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 7.80409e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3300, training loss= 8.161969e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3400, training loss= 5.5696393e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 3.2970627e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 8.763576e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 3700, training loss= 4.7847116e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 3800, training loss= 6.593805e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 3900, training loss= 4.6044188e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 4.8277332e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 3.8972863e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 4.126466e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4300, training loss= 4.9542392e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4400, training loss= 3.5367608e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4500, training loss= 1.985223e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 5.5880606e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 3.2430893e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 4800, training loss= 3.910794e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 4900, training loss= 2.018158e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 2.5018284e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 3.3676028e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 2.0947302e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 2.6408117e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 2.6051965e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 3.1301573e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5600, training loss= 2.367336e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5700, training loss= 2.049514e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 5800, training loss= 9.990617e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 8.0822365e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 1.5722264e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 1.2119383e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 1.2337974e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 9.168887e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6400, training loss= 1.6381538e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 1.9810032e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 7.81372e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6700, training loss= 8.688743e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 1.10711435e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 1.0865252e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 5.9742338e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7100, training loss= 4.7527224e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7200, training loss= 6.2080694e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7300, training loss= 8.884138e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 6.293933e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 7.51772e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 7.38424e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 2.1105293e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 6.9539697e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 7900, training loss= 3.7264176e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 4.755928e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 5.063937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8200, training loss= 3.9288493e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8300, training loss= 3.2804019e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 8400, training loss= 3.0751528e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 6.550676e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 3.4777236e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8700, training loss= 5.084731e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 2.4777005e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 3.0058607e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 1.4986039e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 3.1463794e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 2.966666e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 1.2074029e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9400, training loss= 1.7817259e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 1.3650937e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 2.261265e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 2.7514195e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 2.3318578e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 1.5875698e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 1.1644014e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10100, training loss= 2.048308e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 1.4952833e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 8.9976413e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 1.2329394e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 1.6770747e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10600, training loss= 8.1129633e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 4.567388e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 10800, training loss= 1.5798327e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 8.6085134e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 9.19009e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 4.133988e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 1.034042e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 7.367038e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 1.0818939e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 7.5007466e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 5.320095e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 7.200197e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 7.127799e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 8.553963e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 2.6966734e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 12100, training loss= 6.839999e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 7.735665e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 3.3514695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 3.4425798e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 4.8849995e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 5.039107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 3.1777643e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 5.136189e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 4.8475374e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 2.1219216e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 2.5544762e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13200, training loss= 2.1661975e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 3.8921604e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 2.0197416e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 1.7804719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 2.8303603e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 2.932538e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 1.7200168e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 2.0691259e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 1.8562555e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 1.4168852e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 2.4863567e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 1.7915418e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 9.84327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 9.809205e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 8.617114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 1.2568043e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 8.6086054e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 7.4590886e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 6.914132e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 8.3786965e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 8.4979106e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 6.335113e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.04222835e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 5.6539225e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 7.833745e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 6.2669976e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 6.811953e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 5.006787e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 4.4958913e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 4.9982724e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16200, training loss= 4.2489567e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 5.8923415e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 5.177086e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 4.7939146e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 5.160056e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 3.1335006e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 5.2196604e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 3.712516e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 1.975468e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 2.7929026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 3.031321e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 4.1552934e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 2.2138865e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.907348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 2.1457664e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 2.1117069e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 1.9414083e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 1.805169e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 1.3283319e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 2.7247832e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 2.1372518e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 2.656663e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 1.29427224e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 1.3283319e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 1.2857571e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 1.4560561e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 1.5667505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 1.3027872e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 1.8392285e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 8.855547e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 1.1239732e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 1.0813985e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 7.833753e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 5.108969e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 6.4713612e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 1.2261525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.69999694824219 ...\n",
            "\n",
            "step 20000, training loss= 9.196145e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 5.7901652e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 8.174351e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 7.493155e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 4.4277733e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 5.108969e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 3.32083e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 3.7465777e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 3.0653815e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23000, training loss= 2.7247837e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 2.0435877e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 2.2990363e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 3.4059797e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23500, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 1.7029899e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 1.0217939e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 1.3623919e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 1.3623918e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 6.8119593e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 3.4059797e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.24474247, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 96.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.032282036, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 5.73278e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 26600, training loss= 0.00030204258, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 26700, training loss= 4.8327554e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 26800, training loss= 0.0003888717, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 8.557337e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 1.0821099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27100, training loss= 9.114718e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27200, training loss= 6.6440302e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27300, training loss= 2.1565978e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27400, training loss= 1.7132148e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27500, training loss= 1.2015865e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27600, training loss= 7.938417e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27700, training loss= 8.493593e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27800, training loss= 6.0402754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 27900, training loss= 1.7332968e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28000, training loss= 5.8008377e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28100, training loss= 7.557258e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28200, training loss= 1.0585328e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28300, training loss= 3.2737814e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28400, training loss= 1.2189442e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28500, training loss= 1.4599065e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28600, training loss= 4.4164253e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28700, training loss= 3.0639646e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28800, training loss= 2.4838625e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 28900, training loss= 1.8142007e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29000, training loss= 8.375978e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29100, training loss= 2.4958329e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29200, training loss= 2.5601869e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29300, training loss= 7.4032455e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29400, training loss= 6.6567754e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29500, training loss= 5.7429356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29600, training loss= 8.500388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29700, training loss= 6.127682e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "step 29800, training loss= 1.6215455e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 29900, training loss= 1.1230701e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 97.39999389648438 ...\n",
            "\n",
            "Valid acc= 98.7 %\n",
            "Validation Accuracy Test 98.51380157470703 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.3563504, training acc= 89.99999761581421%\n",
            "Validation Accuracy valid 88.0 ...\n",
            "\n",
            "step 100, training loss= 0.0013517543, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 200, training loss= 0.046949483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 96.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.015602395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.0010993601, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 500, training loss= 0.00060543907, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 600, training loss= 0.035742156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.02051982, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 800, training loss= 0.0003255704, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 900, training loss= 0.002698314, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1000, training loss= 0.00090309983, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 1100, training loss= 0.0007421032, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 1200, training loss= 0.00023186239, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1300, training loss= 0.0002514339, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1400, training loss= 0.000115245464, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1500, training loss= 0.00015637734, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1600, training loss= 8.212202e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1700, training loss= 0.00014769404, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1800, training loss= 0.00014291928, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 1900, training loss= 7.7071294e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2000, training loss= 8.413261e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2100, training loss= 6.18306e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2200, training loss= 8.244873e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2300, training loss= 7.1835784e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2400, training loss= 0.00014239793, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2500, training loss= 0.00011172854, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 2600, training loss= 4.0016163e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2700, training loss= 3.7728772e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 2800, training loss= 4.3896995e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 2900, training loss= 3.8974944e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0 ...\n",
            "\n",
            "step 3000, training loss= 4.320103e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3100, training loss= 6.5506516e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3200, training loss= 3.630137e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3300, training loss= 8.348236e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3400, training loss= 4.6463654e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3500, training loss= 4.73913e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3600, training loss= 4.9050643e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3700, training loss= 3.443583e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.0999984741211 ...\n",
            "\n",
            "step 3800, training loss= 5.295749e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 3900, training loss= 2.9115756e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4000, training loss= 4.7335463e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4100, training loss= 3.3563843e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4200, training loss= 7.086432e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4300, training loss= 3.7008376e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4400, training loss= 2.1530515e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4500, training loss= 5.4621105e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4600, training loss= 3.8189406e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4700, training loss= 2.090024e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 4800, training loss= 3.822282e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 4900, training loss= 3.6192174e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5000, training loss= 2.9120765e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5100, training loss= 3.4396213e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5200, training loss= 4.3570755e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5300, training loss= 1.8151382e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5400, training loss= 2.6990412e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5500, training loss= 2.3288716e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 5600, training loss= 2.3502238e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5700, training loss= 3.2518095e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5800, training loss= 1.6441714e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 5900, training loss= 2.6492204e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6000, training loss= 1.2933482e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6100, training loss= 3.7795922e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6200, training loss= 2.8690403e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6300, training loss= 1.6910099e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6400, training loss= 4.06955e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6500, training loss= 1.0182362e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6600, training loss= 1.7673021e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6700, training loss= 1.2118496e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 6800, training loss= 1.5177543e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 6900, training loss= 1.828235e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7000, training loss= 1.4597936e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7100, training loss= 1.6470447e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7200, training loss= 2.1047e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7300, training loss= 1.4996771e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 7400, training loss= 1.1297304e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7500, training loss= 2.5014371e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7600, training loss= 1.3697337e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7700, training loss= 1.5776854e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7800, training loss= 2.1273268e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 7900, training loss= 9.753624e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8000, training loss= 5.9416693e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8100, training loss= 1.307189e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 8200, training loss= 1.0839659e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8300, training loss= 7.0077126e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8400, training loss= 7.5698817e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8500, training loss= 7.5104426e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8600, training loss= 1.3171199e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8700, training loss= 4.5427187e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8800, training loss= 4.0951795e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 8900, training loss= 7.323114e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9000, training loss= 8.55921e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9100, training loss= 1.0194833e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9200, training loss= 5.873782e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9300, training loss= 6.6927596e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9400, training loss= 2.1024396e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9500, training loss= 3.8785356e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9600, training loss= 3.2273388e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9700, training loss= 5.3128606e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 9800, training loss= 5.273568e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 9900, training loss= 4.140481e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10000, training loss= 5.284792e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10100, training loss= 5.9459653e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10200, training loss= 5.5585815e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10300, training loss= 2.6425023e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10400, training loss= 4.1130966e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10500, training loss= 2.938506e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10600, training loss= 3.3039228e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10700, training loss= 4.156696e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 10800, training loss= 2.800087e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 10900, training loss= 2.8784414e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11000, training loss= 4.6066193e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11100, training loss= 2.2186498e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11200, training loss= 4.17659e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11300, training loss= 3.9410666e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11400, training loss= 3.8625662e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11500, training loss= 2.8251538e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 11600, training loss= 1.9006941e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11700, training loss= 2.1492651e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11800, training loss= 1.2465964e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 11900, training loss= 9.211739e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12000, training loss= 2.5813542e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12100, training loss= 1.2170963e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12200, training loss= 1.289801e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12300, training loss= 1.2382616e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12400, training loss= 1.4377094e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12500, training loss= 1.1516122e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12600, training loss= 1.3979792e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12700, training loss= 1.3319154e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 12800, training loss= 7.256767e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 12900, training loss= 1.0221991e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13000, training loss= 7.5279627e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13100, training loss= 8.2810675e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13200, training loss= 9.0776246e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.19999694824219 ...\n",
            "\n",
            "step 13300, training loss= 4.2489964e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13400, training loss= 7.548806e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13500, training loss= 7.855719e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13600, training loss= 8.304287e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13700, training loss= 6.607124e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13800, training loss= 3.659695e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 13900, training loss= 3.7520888e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14000, training loss= 6.347845e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 5.280196e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14200, training loss= 6.4469117e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14300, training loss= 3.9212117e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14400, training loss= 1.0348688e-06, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14500, training loss= 4.830923e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 5.755484e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14700, training loss= 2.9384975e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 14800, training loss= 3.433214e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 3.611269e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 3.2983607e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15100, training loss= 2.479542e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 1.9580064e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 4.0672444e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 1.3351415e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15500, training loss= 3.5554007e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 15600, training loss= 3.6067885e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 2.0205908e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 2.5637343e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 15900, training loss= 3.573278e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16000, training loss= 1.5765391e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 2.2977463e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 1.8179368e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 1.5884589e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 2.0980778e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 9.9241525e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 16600, training loss= 2.3901367e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 1.630183e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16800, training loss= 9.4473165e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 16900, training loss= 1.1891107e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17000, training loss= 1.3142795e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17100, training loss= 1.364943e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 9.097145e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17300, training loss= 1.4454085e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17400, training loss= 7.8380026e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 1.0490401e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17600, training loss= 1.2606354e-07, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 17700, training loss= 6.884327e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 17800, training loss= 8.039163e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 17900, training loss= 7.27176e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18000, training loss= 6.7353156e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18100, training loss= 6.586307e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18200, training loss= 6.288281e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18300, training loss= 4.3287837e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18400, training loss= 8.493653e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 5.692239e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18600, training loss= 4.731114e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18700, training loss= 2.8014174e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 18800, training loss= 7.3760674e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 18900, training loss= 5.9306558e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 3.4272652e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19100, training loss= 3.09944e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19200, training loss= 3.6954862e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19300, training loss= 1.7881389e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 19400, training loss= 4.6491586e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 3.159045e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 2.7418128e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 3.397464e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 3.2186495e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 19900, training loss= 2.6226035e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 2.5033941e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 2.3841853e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20200, training loss= 1.795589e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20300, training loss= 1.9744032e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20400, training loss= 1.9147986e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 2.175569e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.29999542236328 ...\n",
            "\n",
            "step 20600, training loss= 2.2351733e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 1.996755e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20800, training loss= 1.9371505e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 20900, training loss= 1.788139e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21000, training loss= 1.907348e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21100, training loss= 1.4007088e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21200, training loss= 1.4454123e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 1.311302e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21400, training loss= 8.940692e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21500, training loss= 1.43051135e-08, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21600, training loss= 9.536741e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 5.960464e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 21800, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 4.768371e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 7.1525563e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22400, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22500, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22600, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22700, training loss= 8.642672e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 8.940695e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 22900, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23000, training loss= 5.3644174e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23100, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23200, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 4.4703476e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 4.2468304e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 3.5762782e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23600, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23700, training loss= 5.0663944e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23800, training loss= 4.7683715e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 23900, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 4.1723247e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24100, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 4.470348e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24300, training loss= 2.6822087e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24400, training loss= 3.5762784e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24500, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24600, training loss= 3.2782552e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24700, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 3.8743018e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 24900, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25000, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25100, training loss= 2.3841857e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25200, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25300, training loss= 1.1920928e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25400, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25600, training loss= 1.1920929e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25700, training loss= 2.0861624e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25800, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 25900, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26000, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26100, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26200, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26400, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 1.7881392e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 26900, training loss= 8.940696e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27300, training loss= 1.490116e-09, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27400, training loss= 0.0, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27500, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27600, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27700, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27800, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 27900, training loss= 2.9802322e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5 ...\n",
            "\n",
            "step 28000, training loss= 5.9604643e-10, training acc= 100.0%\n",
            "Validation Accuracy valid 98.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 1.0501016, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 94.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.00021391657, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 0.1540282, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 97.5 ...\n",
            "\n",
            "step 28400, training loss= 0.00055521145, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28500, training loss= 3.4036017e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.29999542236328 ...\n",
            "\n",
            "step 28600, training loss= 0.001800267, training acc= 100.0%\n",
            "Validation Accuracy valid 97.89999389648438 ...\n",
            "\n",
            "step 28700, training loss= 0.0073885997, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 28800, training loss= 0.0033072354, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 28900, training loss= 0.00026740984, training acc= 100.0%\n",
            "Validation Accuracy valid 97.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.0043647327, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29100, training loss= 0.00016933345, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29200, training loss= 0.00020177083, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29300, training loss= 0.0009964005, training acc= 100.0%\n",
            "Validation Accuracy valid 97.69999694824219 ...\n",
            "\n",
            "step 29400, training loss= 1.4938123e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29500, training loss= 9.6338714e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29600, training loss= 5.6149547e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29700, training loss= 5.3622192e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29800, training loss= 0.00013764083, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "step 29900, training loss= 4.4615026e-05, training acc= 100.0%\n",
            "Validation Accuracy valid 97.79999542236328 ...\n",
            "\n",
            "Valid acc= 98.6 %\n",
            "Validation Accuracy Test 98.93843078613281 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.9294039, training acc= 87.99999952316284%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-1286d8755697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", training loss= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\", training acc= \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mvalidation_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid_validation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalid_validation_data_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mplot_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy valid {} ...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BoQHpkHzQ0YO"
      },
      "cell_type": "markdown",
      "source": [
        "#### Valid acc= 98.799995 %\n",
        "#### Validation Accuracy Test 98.51380157470703 ...\n",
        "W1 = 4 ...\n",
        "W2 = 1 ...\n",
        "W3 = 0 ...\n",
        "Highest validation accuracy, to brake tie Validation test accuracy was used which is highest for this combination"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tsk4HwnCPtR3"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SeaxvipDvrKA"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jz2-ZZrWPz1c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max(ValidAccuracy_Track)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VTX6kBhaPzyc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aXUrVrDqPzum",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qDiB6tNU4DUq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SW9qZGWUQFQs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Test_track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oWFUJtzdQFQx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Test_track],bins=30)\n",
        "plt.ylabel('Iter')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5nSzdyLhJ3K-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}